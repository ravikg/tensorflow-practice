{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function to sentence(word seq.) to char seq(space is treated as special characted)\n",
    "SPACE = \"_SPACE_\"\n",
    "def char_seq(sentence) :\n",
    "    char_seq_output = \"\"\n",
    "    for c in sentence:\n",
    "        char_seq_output += \" \"\n",
    "        if c == \" \":\n",
    "            char_seq_output += SPACE\n",
    "        else:\n",
    "            char_seq_output += c\n",
    "    return char_seq_output.lstrip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d _SPACE_ u v w x y z', '1 2 3 _SPACE_ 9 8 7']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(char_seq, [\"abcd uvwxyz\", \"123 987\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "{'_space_': 1, 'e': 2, 't': 3, 'a': 4, 'o': 5, 'i': 6, 'n': 7, 'h': 8, 's': 9, 'r': 10, 'd': 11, 'l': 12, 'u': 13, 'c': 14, 'w': 15, 'g': 16, 'y': 17, ',': 18, 'm': 19, 'f': 20, 'p': 21, '’': 22, 'b': 23, 'k': 24, '.': 25, '‘': 26, 'v': 27, '-': 28, '!': 29, ':': 30, 'j': 31, 'q': 32, '?': 33, ';': 34, 'x': 35, '*': 36, 'z': 37, ')': 38, '“': 39, '(': 40, '1': 41, '”': 42, '/': 43, '0': 44, '5': 45, '3': 46, '2': 47, '8': 48, '9': 49, '4': 50, '6': 51, '[': 52, '7': 53, '_': 54, ']': 55, '@': 56, '$': 57, '#': 58, '%': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > project gutenberg’s alice’s adventures in wonderland , by lewis carroll\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > this ebook is for the use of anyone anywhere at no cost and with\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the input data : alice.en\n",
    "with open('./data/alice.en') as f:\n",
    "    input_lines = f.read().splitlines()\n",
    "    input_lines_cs = list(map(char_seq, input_lines))\n",
    "print('no. of lines {}'.format(len(input_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "en_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "en_tokenizer.fit_on_texts(input_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print(en_tokenizer.word_index)\n",
    "\n",
    "# get sequences\n",
    "input_seqs = en_tokenizer.texts_to_sequences(input_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(input_lines[:2], input_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_tokenizer.word_index)\n",
    "type(input_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy\\nprint(input_seqs[:10])\\ninput_seqs_np = numpy.array([numpy.array(xi) for xi in input_seqs])\\nprint(input_seqs_np)\\ntype(input_seqs_np)\\n#input_seqs_tensor = tf.convert_to_tensor(input_seqs_np)\\n#print(input_seqs_tensor)\\nbatched_data = tf.train.batch(\\n    tensors=[input_seqs_np],\\n    batch_size=10,\\n    dynamic_pad=True,\\n    name=\"input_seq_batch\"\\n)\\n# Run the graph\\n# tf.contrib.learn takes care of starting the queues for us\\nres = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\\n# Print the result\\n#print(\"Batch shape: {}\".format(res[0][\"y\"].shape))\\nprint(res[0][\"y\"])\\nprint(res[0])\\nres.shape\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying use batch method from tensorflow\n",
    "'''\n",
    "import numpy\n",
    "print(input_seqs[:10])\n",
    "input_seqs_np = numpy.array([numpy.array(xi) for xi in input_seqs])\n",
    "print(input_seqs_np)\n",
    "type(input_seqs_np)\n",
    "#input_seqs_tensor = tf.convert_to_tensor(input_seqs_np)\n",
    "#print(input_seqs_tensor)\n",
    "batched_data = tf.train.batch(\n",
    "    tensors=[input_seqs_np],\n",
    "    batch_size=10,\n",
    "    dynamic_pad=True,\n",
    "    name=\"input_seq_batch\"\n",
    ")\n",
    "# Run the graph\n",
    "# tf.contrib.learn takes care of starting the queues for us\n",
    "res = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n",
    "# Print the result\n",
    "#print(\"Batch shape: {}\".format(res[0][\"y\"].shape))\n",
    "print(res[0][\"y\"])\n",
    "print(res[0])\n",
    "res.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "vocabulary size: 59\n",
      "vocabulary: {'_space_': 1, '5': 2, 'x': 3, '4': 4, 'w': 5, 'f': 6, '?': 7, ']': 8, 'u': 9, 'c': 10, 't': 11, '-': 12, '6': 13, '7': 14, 'r': 15, '’': 16, '[': 17, '$': 18, ':': 19, ';': 20, 's': 21, '”': 22, 'e': 23, '!': 24, 'q': 25, '_': 26, '/': 27, '1': 28, '#': 29, 'p': 30, '%': 31, 'v': 32, 'k': 33, '9': 34, '“': 35, 'b': 36, '‘': 37, 'd': 38, '8': 39, 'z': 40, 'y': 41, ')': 42, '2': 43, '(': 44, '3': 45, 'l': 46, 'h': 47, 'g': 48, 'o': 49, 'j': 50, ',': 51, 'm': 52, '0': 53, '.': 54, '@': 55, '*': 56, 'n': 57, 'i': 58, 'a': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > scw%57x ’6x5?e5c’”u 4-f75”u 4t/5?x6c5u f? rw?t5c-4?t $ e[ -5rfu 74ccw--\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > x]fu 5eww! fu ;wc x]5 6u5 w; 4?[w?5 4?[r]5c5 4x ?w 7wux 4?t rfx]\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the output data : alice.x\n",
    "with open('./data/alice.x') as f:\n",
    "    output_lines = f.read().splitlines()\n",
    "    output_lines_cs = list(map(char_seq, output_lines))\n",
    "print('no. of lines {}'.format(len(output_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "x_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "x_tokenizer.fit_on_texts(output_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print('vocabulary size: {}'.format(len(x_tokenizer.word_index)))\n",
    "print('vocabulary: {}'.format(x_tokenizer.word_index))\n",
    "\n",
    "# get sequences\n",
    "output_seqs = x_tokenizer.texts_to_sequences(output_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(output_lines[:2], output_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do batching\n",
    "import helpers\n",
    "xt, xlen = helpers.batch(input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  3  4 ...,  6  4  9]\n",
      " [10  8 12 ...,  7 10 13]\n",
      " [ 5  6 19 ..., 14 14 23]\n",
      " ..., \n",
      " [ 1  5  7 ...,  7  1 23]\n",
      " [16  5  5 ..., 16 20  2]\n",
      " [13 24  1 ...,  1  5  1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(xt[:10])\n",
    "print(type(xt))\n",
    "print(type(xt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1 # this is not being used\n",
    "\n",
    "vocab_size = len(en_tokenizer.word_index)\n",
    "input_embedding_size = 16 # 20 or 32\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholders for encoder inputs, decoder input and decoder targets\n",
    "# we don't define the shape (size) of encoder inputs / decoder targets as it will depend on batch size\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "# similarly decoder inputs' shape (size) is dynamic - batch dependent\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "# ^^^ gets map to previous decoder output during rollout - but during training we want to \n",
    "#   input the target inspite of whatever the decoder output is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random initialization of embedding\n",
    "# word embedding help us reduce the dimension of data for network training\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to understand how this embedding look up works ??\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" now we don't delete encoder_output as it will be use in attention for decoder\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define encoder cell - using an LSTMCell\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "# defined attention length randomnly - need to analysis the input data and maybe define based on that\n",
    "attention_length = 10 \n",
    "# add a attention wrapper around encoder cell\n",
    "encoder_cell_w_attention = tf.contrib.rnn.AttentionCellWrapper(encoder_cell, attention_length, state_is_tuple=True)\n",
    "# define encoder rnn\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell_w_attention, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "\n",
    "''' now we don't delete encoder_output as it will be use in attention for decoder'''\n",
    "#del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 20) dtype=float32>),\n",
       " <tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 20) dtype=float32>,\n",
       " <tf.Tensor 'rnn/while/Exit_5:0' shape=(?, 200) dtype=float32>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state # context vector or thought vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define decoder cell - using an LSTMCell\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "decoder_cell_attn = tf.contrib.rnn.AttentionCellWrapper(decoder_cell, attention_length, state_is_tuple=True)\n",
    "# define decoder RNN\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell_attn, decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ = input_seqs[:10]#[[6], [3, 4], [9, 8, 7]]\n",
    "dbatch_ = output_seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbatch_, batch_length_ = helpers.batch(batch_)\\nprint('batch_encoded:\\n' + str(batch_))\\n\\n\\ndin_, dlen_ = helpers.batch(dbatch_)\\nprint('decoder inputs:\\n' + str(din_))\\n\\npred_ = sess.run(decoder_prediction,\\n    feed_dict={\\n        encoder_inputs: batch_,\\n        decoder_inputs: din_,\\n    })\\nprint('decoder predictions:\\n' + str(pred_))\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "batch_, batch_length_ = helpers.batch(batch_)\n",
    "print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "\n",
    "din_, dlen_ = helpers.batch(dbatch_)\n",
    "print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "pred_ = sess.run(decoder_prediction,\n",
    "    feed_dict={\n",
    "        encoder_inputs: batch_,\n",
    "        decoder_inputs: din_,\n",
    "    })\n",
    "print('decoder predictions:\\n' + str(pred_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get batch data\n",
    "def next_feed(batch_seq, input_seqs, output_seqs):\n",
    "    start = batch_seq*10\n",
    "    end = (batch_seq+1)*10\n",
    "    batch_ = input_seqs[start:end]\n",
    "    #print(batch_)\n",
    "    dbatch_ = output_seqs[start:end]\n",
    "    #print(batch_)\n",
    "    encoder_inputs_, _ = helpers.batch(batch_)\n",
    "    decoder_targets_, _ = helpers.batch(dbatch_)\n",
    "    decoder_inputs_, _ = helpers.batch(dbatch_)\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch 1:\n",
      "batch 0\n",
      "  minibatch loss: 4.058338642120361\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [14 51 51 51 29 51 42  2  2 16 42 42  3 58  3 13 13  3 25 44 16 16 16 16 42\n",
      "  3 46 17 46 42 42 56 56 56  3 42 29 56 44 24  2  2 44 56 56 21 29 24 29 51\n",
      " 29 29  2 29  2  2 58 17 16 29 29 29 16 17 13 16 16 13 42 42 42]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [42 51 42 42 44 42 44 42 42 42 56 21 41 44 56 56 51 51 51 51 21 41 21 51 21\n",
      " 41 41 41 41 51 41 21 21 21 21 21 21 21 21 21 21 21 24 24 24 51 42 26 56 56\n",
      " 44 44 56 51 42 44 44 21 21 21 21 21 42 42 56 56 56 56 56 42 42]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.6094520092010498\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  6  6  1  1  1  2  3  1  2  1  1  5  5  3  2  1  1  4  1  2  1  3  5\n",
      "  3  2  1  3  3  3  1  3  1  4  3  1  2  1  7  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  6  7  2  1  1  2  2  7  1  3  1  2  1  2  1  3  3  3  7  4  1\n",
      "  7  1  3  1  1  4  3  3  1  4  6  6  1  2  1  7  1  2  1  5  1  2  1  3  1\n",
      "  5  5  5  1  3  1  1  2  2  2  2  1  1  3  3  3  3  1  2  3  7  7  3  7  1]\n",
      "\n",
      "==> epoch 2:\n",
      "batch 0\n",
      "  minibatch loss: 1.5744004249572754\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.5412294268608093\n",
      "\n",
      "==> epoch 3:\n",
      "batch 0\n",
      "  minibatch loss: 0.7388906478881836\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.20316380262374878\n",
      "\n",
      "==> epoch 4:\n",
      "batch 0\n",
      "  minibatch loss: 0.5180977582931519\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.09884592890739441\n",
      "\n",
      "==> epoch 5:\n",
      "batch 0\n",
      "  minibatch loss: 0.4513264298439026\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.05689671263098717\n",
      "\n",
      "==> epoch 6:\n",
      "batch 0\n",
      "  minibatch loss: 0.40742233395576477\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.03804576024413109\n",
      "\n",
      "==> epoch 7:\n",
      "batch 0\n",
      "  minibatch loss: 0.37454304099082947\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.026075733825564384\n",
      "\n",
      "==> epoch 8:\n",
      "batch 0\n",
      "  minibatch loss: 0.3511919379234314\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.019226357340812683\n",
      "\n",
      "==> epoch 9:\n",
      "batch 0\n",
      "  minibatch loss: 0.3256432116031647\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.014379576779901981\n",
      "\n",
      "==> epoch 10:\n",
      "batch 0\n",
      "  minibatch loss: 0.2992072105407715\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.010858985595405102\n",
      "\n",
      "==> epoch 11:\n",
      "batch 0\n",
      "  minibatch loss: 0.2745538353919983\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.00836531724780798\n",
      "\n",
      "==> epoch 12:\n",
      "batch 0\n",
      "  minibatch loss: 0.2500661313533783\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.00658760080114007\n",
      "\n",
      "==> epoch 13:\n",
      "batch 0\n",
      "  minibatch loss: 0.22503092885017395\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.005242166109383106\n",
      "\n",
      "==> epoch 14:\n",
      "batch 0\n",
      "  minibatch loss: 0.20043060183525085\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.004258465021848679\n",
      "\n",
      "==> epoch 15:\n",
      "batch 0\n",
      "  minibatch loss: 0.1760197877883911\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0035196663811802864\n",
      "\n",
      "==> epoch 16:\n",
      "batch 0\n",
      "  minibatch loss: 0.1537395715713501\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0029432668816298246\n",
      "\n",
      "==> epoch 17:\n",
      "batch 0\n",
      "  minibatch loss: 0.13310837745666504\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0025110901333391666\n",
      "\n",
      "==> epoch 18:\n",
      "batch 0\n",
      "  minibatch loss: 0.11467558145523071\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.002151239663362503\n",
      "\n",
      "==> epoch 19:\n",
      "batch 0\n",
      "  minibatch loss: 0.10062237828969955\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0019516878528520465\n",
      "\n",
      "==> epoch 20:\n",
      "batch 0\n",
      "  minibatch loss: 0.08696065098047256\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0016756110126152635\n",
      "\n",
      "==> epoch 21:\n",
      "batch 0\n",
      "  minibatch loss: 0.0779714584350586\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0015456902328878641\n",
      "\n",
      "==> epoch 22:\n",
      "batch 0\n",
      "  minibatch loss: 0.06765973567962646\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0013228383613750339\n",
      "\n",
      "==> epoch 23:\n",
      "batch 0\n",
      "  minibatch loss: 0.0605044849216938\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0011782391229644418\n",
      "\n",
      "==> epoch 24:\n",
      "batch 0\n",
      "  minibatch loss: 0.053803179413080215\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.001014559529721737\n",
      "\n",
      "==> epoch 25:\n",
      "batch 0\n",
      "  minibatch loss: 0.045593008399009705\n",
      "\n",
      "training interrupted\n"
     ]
    }
   ],
   "source": [
    "max_batches = 200\n",
    "batches_in_epoch = 199\n",
    "writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "\n",
    "try:\n",
    "    for epoch in range(50):\n",
    "        print('==> epoch {}:'.format(epoch + 1))\n",
    "        for batch in range(max_batches):\n",
    "            #print(input_seqs)\n",
    "            fd = next_feed(batch, input_seqs, output_seqs)\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                if epoch == 0 or epoch == 25 or epoch == 49:\n",
    "                    for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                        print('  sample {}:'.format(i + 1))\n",
    "                        print('    input     > {}'.format(inp))\n",
    "                        print('    predicted > {}'.format(pred))\n",
    "                        if i >= 1:\n",
    "                            break\n",
    "                print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0006 after 49080 examples (batch_size=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu4hIBCncRUQiSOEuIhJBCncRkQj6/7pUgaUbH23VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1141d44a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
