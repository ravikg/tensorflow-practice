{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function to sentence(word seq.) to char seq(space is treated as special characted)\n",
    "SPACE = \"_SPACE_\"\n",
    "def char_seq(sentence) :\n",
    "    char_seq_output = \"\"\n",
    "    for c in sentence:\n",
    "        char_seq_output += \" \"\n",
    "        if c == \" \":\n",
    "            char_seq_output += SPACE\n",
    "        else:\n",
    "            char_seq_output += c\n",
    "    return char_seq_output.lstrip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d _SPACE_ u v w x y z', '1 2 3 _SPACE_ 9 8 7']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(char_seq, [\"abcd uvwxyz\", \"123 987\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "{'_space_': 1, 'e': 2, 't': 3, 'a': 4, 'o': 5, 'i': 6, 'n': 7, 'h': 8, 's': 9, 'r': 10, 'd': 11, 'l': 12, 'u': 13, 'c': 14, 'w': 15, 'g': 16, 'y': 17, ',': 18, 'm': 19, 'f': 20, 'p': 21, '’': 22, 'b': 23, 'k': 24, '.': 25, '‘': 26, 'v': 27, '-': 28, '!': 29, ':': 30, 'j': 31, 'q': 32, '?': 33, ';': 34, 'x': 35, '*': 36, 'z': 37, ')': 38, '“': 39, '(': 40, '1': 41, '”': 42, '/': 43, '0': 44, '5': 45, '3': 46, '2': 47, '8': 48, '9': 49, '4': 50, '6': 51, '[': 52, '7': 53, '_': 54, ']': 55, '@': 56, '$': 57, '#': 58, '%': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > project gutenberg’s alice’s adventures in wonderland , by lewis carroll\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > this ebook is for the use of anyone anywhere at no cost and with\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the input data : alice.en\n",
    "with open('./data/alice.en') as f:\n",
    "    input_lines = f.read().splitlines()\n",
    "    input_lines_cs = list(map(char_seq, input_lines))\n",
    "print('no. of lines {}'.format(len(input_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "en_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "en_tokenizer.fit_on_texts(input_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print(en_tokenizer.word_index)\n",
    "\n",
    "# get sequences\n",
    "input_seqs = en_tokenizer.texts_to_sequences(input_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(input_lines[:2], input_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_tokenizer.word_index)\n",
    "type(input_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "vocabulary size: 59\n",
      "vocabulary: {'_space_': 1, '5': 2, 'x': 3, '4': 4, 'w': 5, 'f': 6, '?': 7, ']': 8, 'u': 9, 'c': 10, 't': 11, '-': 12, '6': 13, '7': 14, 'r': 15, '’': 16, '[': 17, '$': 18, ':': 19, ';': 20, 's': 21, '”': 22, 'e': 23, '!': 24, 'q': 25, '_': 26, '/': 27, '1': 28, '#': 29, 'p': 30, '%': 31, 'v': 32, 'k': 33, '9': 34, '“': 35, 'b': 36, '‘': 37, 'd': 38, '8': 39, 'z': 40, 'y': 41, ')': 42, '2': 43, '(': 44, '3': 45, 'l': 46, 'h': 47, 'g': 48, 'o': 49, 'j': 50, ',': 51, 'm': 52, '0': 53, '.': 54, '@': 55, '*': 56, 'n': 57, 'i': 58, 'a': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > scw%57x ’6x5?e5c’”u 4-f75”u 4t/5?x6c5u f? rw?t5c-4?t $ e[ -5rfu 74ccw--\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > x]fu 5eww! fu ;wc x]5 6u5 w; 4?[w?5 4?[r]5c5 4x ?w 7wux 4?t rfx]\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the output data : alice.x\n",
    "with open('./data/alice.x') as f:\n",
    "    output_lines = f.read().splitlines()\n",
    "    output_lines_cs = list(map(char_seq, output_lines))\n",
    "print('no. of lines {}'.format(len(output_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "x_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "x_tokenizer.fit_on_texts(output_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print('vocabulary size: {}'.format(len(x_tokenizer.word_index)))\n",
    "print('vocabulary: {}'.format(x_tokenizer.word_index))\n",
    "\n",
    "# get sequences\n",
    "output_seqs = x_tokenizer.texts_to_sequences(output_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(output_lines[:2], output_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1 # this is not being used\n",
    "\n",
    "vocab_size = len(en_tokenizer.word_index) + 1\n",
    "input_embedding_size = 16 # 20 or 32\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholders for encoder inputs, decoder input and decoder targets\n",
    "# we don't define the shape (size) of encoder inputs / decoder targets as it will depend on batch size\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "# similarly decoder inputs' shape (size) is dynamic - batch dependent\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "# ^^^ gets map to previous decoder output during rollout - but during training we want to \n",
    "#   input the target inspite of whatever the decoder output is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random initialization of embedding\n",
    "# word embedding help us reduce the dimension of data for network training\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to understand how this embedding look up works ??\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder cell - using an LSTMCell\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "# defined attention length randomnly - need to analysis the input data and maybe define based on that\n",
    "attention_length = 10 \n",
    "# add a attention wrapper around encoder cell\n",
    "encoder_cell_w_attention = tf.contrib.rnn.AttentionCellWrapper(encoder_cell, attention_length, state_is_tuple=True)\n",
    "# define encoder rnn\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell_w_attention, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define decoder cell - using an LSTMCell\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "decoder_cell_attn = tf.contrib.rnn.AttentionCellWrapper(decoder_cell, attention_length, state_is_tuple=True)\n",
    "# define decoder RNN\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell_attn, decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get batch data\n",
    "def next_feed(batch_seq, input_seqs, output_seqs, batch_size):\n",
    "    start = batch_seq * batch_size\n",
    "    end = (batch_seq + 1) * batch_size\n",
    "    batch_ = input_seqs[start:end]\n",
    "    #print(batch_)\n",
    "    dbatch_ = output_seqs[start:end]\n",
    "    #print(batch_)\n",
    "    encoder_inputs_, _ = helpers.batch(batch_)\n",
    "    decoder_targets_, _ = helpers.batch(dbatch_)\n",
    "    decoder_inputs_, _ = helpers.batch(dbatch_)\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 200)\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "batch_size = 10\n",
    "max_batches = 200\n",
    "batches_in_epoch = 199\n",
    "training_data_size = max_batches * batch_size # 2000\n",
    "\n",
    "## get the validation data\n",
    "vd_batch_size = 200\n",
    "vd = next_feed(0, input_seqs[training_data_size:], output_seqs[training_data_size:], vd_batch_size)\n",
    "print(vd[encoder_inputs].shape)\n",
    "vd_loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch 1:\n",
      "batch 0\n",
      "  minibatch loss: 4.028650760650635\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [32 51 45 45  8 55 55 53 18  8  8  8 50 33 33 33 44 37  3  3 12 12 12 23 23\n",
      " 56 47  4 29 29 29 58  4 16 16 16 16 16 16 56 47 16 24 24 59 59 59 59 59 47\n",
      " 47 59  4 31  4 31 47  4  4  4 58 29 29  4 29 29 29 29 29 29 29]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [41 41 41 13 13  8 41 37 45 45 45 12 33 12  7  7 12  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7 56 56 29 29 47 47 29 56 47 47 58 58 58 58 58 58 58 58 58  4  4\n",
      "  4 58 58 58 58  6 58  4 58  4 58 23 23 45 45 56 59 59 59 31 31]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [41 51 57 48  8  8  8 50 43 43 12 12  3  3  7 33 56 56 56 56  7  7  7  7 45\n",
      " 56 56 56  7  7  7  7  7  4 29 29  4 45 45 45 29 56 29 29 29 29 29 29 29 56\n",
      " 56 29 29 29  4 56 29 58 58 56 56  6 56 58 58 58 58 58 58 58 58]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.060978889465332\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [5 1 1 1 1 1 1 2 3 1 6 1 3 1 1 6 6 1 1 1 1 1 1 3 1 3 6 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [ 3 10  1  1  3  1  1  1  3  1  1  1  1  3  1  1  1  1  1  3  3  3  1  1  1\n",
      "  6  1  6  1  1  1  3  3  1  1  3  3  3  1  1  3  1  1  1  1  1  1  1  3  1\n",
      "  1  1  1  1  3  1  1  1  1  6  1  1  1  3  3  6  6  1  3  1  1  1  6  1  1]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [5 1 1 1 1 1 1 1 1 1 1 1 6 1 3 6 6 6 1 1 1 1 1 1 1 1 3 3 1 3 1 1 3 1 1 1 3\n",
      " 1 3 3 1 3 1 1 1 3 1 3 1 1 1 1 3 1 3 1 3 1 1 6 1 6 6 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0]\n",
      "\n",
      "==> epoch 2:\n",
      "batch 0\n",
      "  minibatch loss: 1.9154812097549438\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [3 3 1 1 1 3 1 1 1 1 1 1 1 3 1 3 1 3 1 1 1 6 6 6 1 3 1 1 1 3 1 1 1 3 1 3 1\n",
      " 1 1 3 1 1 1 1 1 6 1 3 6 1 1 6 1 6 1 6 1 1 1 1 1 3 1 1 3 1 6 6 1 6 0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [5 1 3 1 1 1 3 1 1 1 1 3 1 1 3 1 6 1 3 1 1 1 3 1 1 1 1 3 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 3 1 1 1 3 1 1 1 1 3 1 1 3 1 1 1 6 1 1 6 3 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [5 3 1 1 1 1 1 1 1 1 3 1 1 3 3 3 6 3 3 1 1 1 1 1 1 1 3 1 1 1 1 1 3 1 1 1 1\n",
      " 1 3 1 3 1 1 1 6 1 6 1 1 3 3 1 3 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 6 6 0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.9082586169242859\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  4  7  7  1  9  5  6  6 11 14  1  6  5 10 12 11  1  8  4  5  2  1  3  5\n",
      " 12 11  1  7  5 13  1  3  8  4  3  1  0  1 12  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  5  1  6 10 11  1 14  2  2  7  1  3  8  2  1  8  8  6  3  6  7  7  1\n",
      " 18  1 12  1  9  4  6 11  1  4 12  6 14  2  1 18  1  8  8  5  9  2  1  3  8\n",
      "  5 13  5  8  3  9  1  8  2  6  2  1  9  3  6 12 12  1  6 13  7  7  6  7  7]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  5  1  3  8  2  1  9  5  7  5  1 18  1  3  6 12 11  1  8  4  8  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 10  5  6 10  5  6  9  2  1 18  1 12  1 18\n",
      "  2  2  6  1 12  4  6 18  1 18  1 12 12  2  4  9  2  1  6  1  8  2  0  0  0]\n",
      "\n",
      "==> epoch 3:\n",
      "batch 0\n",
      "  minibatch loss: 1.0199121236801147\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  6  5  5  2 14  3  1  7 13  3  2  7 11  2  6  8 12  9  1  4 12  6 14  2\n",
      " 12  9  1  4 11  5  2  7  3 13 10  2  9  1  6  7  1  8  5  7 11  2  6 12  4\n",
      "  7 11  1 18  1 12  7  1 12  2  7  6  9  1 10  4  6 10  1 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2  6  5  5  7  1  6  9  1 13  5  6  1  3  8  2  1 13  9  2\n",
      "  1  5 13  1  4  7  7  5  7  2  1  4  7  7  8  5  2 10  2  1  4  3  1  7  5\n",
      "  1 10  5  9  3  1  4  7 11  1  8  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 11  5  9  3  1  7  5  1  6  2  9  3 10  6 14  3  6  5  7  9  1  8  8\n",
      "  4  3  9  5  2  5  2  6  1 18  1  7  5 13  1 11  4  7  1  6  5 11  7  1  6\n",
      "  3  1 18  1  7  6  5  2  1  6  3  1  4  8  4  7  1  5 12  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.37589457631111145\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 11 14  1 14  5 13 12 11  1  8  4 16  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 26  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7  7]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5 22  1  3  8  2  1  9  5  7 16  1 18  1  6  6 22 11  1  8  4 16  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 10  5 10 13  5  6  9  2  1 18  1 10  1 18\n",
      "  2  2 10  1 10  4 14 24  1 18  1 10 12  2  4  9  2  1  6  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.6628900170326233\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26 10  5 13  2 14  3  1 16 13  3  2  7 11  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 16  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 11 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 10  5  5  7  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 11  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 16  2 10  1 22  1 17  5 13  1 11  4 17  1 14  5 14 17  1  6\n",
      "  3  1 18  1 16  6  5  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.1853305697441101\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 26  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7  9]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5 17  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 20  1 24\n",
      "  2  2 10  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 26  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 5:\n",
      "batch 0\n",
      "  minibatch loss: 0.5376107096672058\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [10 10  5 22  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 16  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 16  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6  5  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.10739016532897949\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7  9]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 20  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 26  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 6:\n",
      "batch 0\n",
      "  minibatch loss: 0.497057169675827\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [20 10  5 22  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6  5  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.06903629750013351\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7  9]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 20  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 7:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.465257853269577\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [20 10  5 32  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6  5  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.04887807369232178\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 21  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 8:\n",
      "batch 0\n",
      "  minibatch loss: 0.43874773383140564\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6  5  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.03553355485200882\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 31  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 9:\n",
      "batch 0\n",
      "  minibatch loss: 0.41295889019966125\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.026359988376498222\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 31  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 10:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.3893945813179016\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.020254261791706085\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 31  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 11:\n",
      "batch 0\n",
      "  minibatch loss: 0.36892545223236084\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.01579994522035122\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 12:\n",
      "batch 0\n",
      "  minibatch loss: 0.35062506794929504\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.012425990775227547\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 13:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.3313395082950592\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.00977003388106823\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 14:\n",
      "batch 0\n",
      "  minibatch loss: 0.3109133243560791\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.007753707468509674\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n",
      "==> epoch 15:\n",
      "batch 0\n",
      "  minibatch loss: 0.2931872606277466\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.00620956951752305\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "\n",
    "try:\n",
    "    for epoch in range(15):\n",
    "        print('==> epoch {}:'.format(epoch + 1))\n",
    "        for batch in range(max_batches):\n",
    "            fd = next_feed(batch, input_seqs, output_seqs, batch_size)\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "            #calculate validation loss\n",
    "            vl = sess.run(loss, vd)\n",
    "            vd_loss_track.append(vl)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0064 after 30000 examples (batch_size=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113b7e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track, 'b', vd_loss_track, 'r')\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on test data\n",
    "# get the test batch\n",
    "total_data_size = len(input_seqs) # 2791\n",
    "train_val_data_size = max_batches * batch_size + vd_batch_size # 2200\n",
    "# test_data = total_data - (training_data + validation_data)\n",
    "test_input_seqs  = input_seqs[train_val_data_size:]\n",
    "test_output_seqs = output_seqs[train_val_data_size:]\n",
    "\n",
    "# sort the test data on len and observe on that\n",
    "tiss = sorted(test_input_seqs, key=len)\n",
    "toss = sorted(test_output_seqs, key=len)\n",
    "\n",
    "# no. of batchess in test data\n",
    "test_batches = len(test_input_seqs) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_track_x = []\n",
    "test_loss_track_y = []\n",
    "\n",
    "for batch in range(int(test_batches)):\n",
    "    fd = next_feed(batch, tiss, toss, batch_size)\n",
    "    ll = len(fd[encoder_inputs])\n",
    "    l = sess.run(loss, fd)\n",
    "    test_loss_track_x.append(ll)\n",
    "    test_loss_track_y.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1149c1dd8>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABJEuANAgv4f/A1yPHj/iAAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11049b630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_loss_track_x, test_loss_track_y, 'ro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
