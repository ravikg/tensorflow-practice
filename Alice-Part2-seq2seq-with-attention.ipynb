{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function to sentence(word seq.) to char seq(space is treated as special characted)\n",
    "SPACE = \"_SPACE_\"\n",
    "def char_seq(sentence) :\n",
    "    char_seq_output = \"\"\n",
    "    for c in sentence:\n",
    "        char_seq_output += \" \"\n",
    "        if c == \" \":\n",
    "            char_seq_output += SPACE\n",
    "        else:\n",
    "            char_seq_output += c\n",
    "    return char_seq_output.lstrip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d _SPACE_ u v w x y z', '1 2 3 _SPACE_ 9 8 7']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(char_seq, [\"abcd uvwxyz\", \"123 987\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "{'_space_': 1, 'e': 2, 't': 3, 'a': 4, 'o': 5, 'i': 6, 'n': 7, 'h': 8, 's': 9, 'r': 10, 'd': 11, 'l': 12, 'u': 13, 'c': 14, 'w': 15, 'g': 16, 'y': 17, ',': 18, 'm': 19, 'f': 20, 'p': 21, '’': 22, 'b': 23, 'k': 24, '.': 25, '‘': 26, 'v': 27, '-': 28, '!': 29, ':': 30, 'j': 31, 'q': 32, '?': 33, ';': 34, 'x': 35, '*': 36, 'z': 37, ')': 38, '“': 39, '(': 40, '1': 41, '”': 42, '/': 43, '0': 44, '5': 45, '3': 46, '2': 47, '8': 48, '9': 49, '4': 50, '6': 51, '[': 52, '7': 53, '_': 54, ']': 55, '@': 56, '$': 57, '#': 58, '%': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > project gutenberg’s alice’s adventures in wonderland , by lewis carroll\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > this ebook is for the use of anyone anywhere at no cost and with\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the input data : alice.en\n",
    "with open('./data/alice.en') as f:\n",
    "    input_lines = f.read().splitlines()\n",
    "    input_lines_cs = list(map(char_seq, input_lines))\n",
    "print('no. of lines {}'.format(len(input_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "en_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "en_tokenizer.fit_on_texts(input_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print(en_tokenizer.word_index)\n",
    "\n",
    "# get sequences\n",
    "input_seqs = en_tokenizer.texts_to_sequences(input_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(input_lines[:2], input_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_tokenizer.word_index)\n",
    "type(input_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "vocabulary size: 59\n",
      "vocabulary: {'_space_': 1, '5': 2, 'x': 3, '4': 4, 'w': 5, 'f': 6, '?': 7, ']': 8, 'u': 9, 'c': 10, 't': 11, '-': 12, '6': 13, '7': 14, 'r': 15, '’': 16, '[': 17, '$': 18, ':': 19, ';': 20, 's': 21, '”': 22, 'e': 23, '!': 24, 'q': 25, '_': 26, '/': 27, '1': 28, '#': 29, 'p': 30, '%': 31, 'v': 32, 'k': 33, '9': 34, '“': 35, 'b': 36, '‘': 37, 'd': 38, '8': 39, 'z': 40, 'y': 41, ')': 42, '2': 43, '(': 44, '3': 45, 'l': 46, 'h': 47, 'g': 48, 'o': 49, 'j': 50, ',': 51, 'm': 52, '0': 53, '.': 54, '@': 55, '*': 56, 'n': 57, 'i': 58, 'a': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > scw%57x ’6x5?e5c’”u 4-f75”u 4t/5?x6c5u f? rw?t5c-4?t $ e[ -5rfu 74ccw--\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > x]fu 5eww! fu ;wc x]5 6u5 w; 4?[w?5 4?[r]5c5 4x ?w 7wux 4?t rfx]\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the output data : alice.x\n",
    "with open('./data/alice.x') as f:\n",
    "    output_lines = f.read().splitlines()\n",
    "    output_lines_cs = list(map(char_seq, output_lines))\n",
    "print('no. of lines {}'.format(len(output_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "x_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "x_tokenizer.fit_on_texts(output_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print('vocabulary size: {}'.format(len(x_tokenizer.word_index)))\n",
    "print('vocabulary: {}'.format(x_tokenizer.word_index))\n",
    "\n",
    "# get sequences\n",
    "output_seqs = x_tokenizer.texts_to_sequences(output_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(output_lines[:2], output_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1 # this is not being used\n",
    "\n",
    "vocab_size = len(en_tokenizer.word_index)\n",
    "input_embedding_size = 16 # 20 or 32\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholders for encoder inputs, decoder input and decoder targets\n",
    "# we don't define the shape (size) of encoder inputs / decoder targets as it will depend on batch size\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "# similarly decoder inputs' shape (size) is dynamic - batch dependent\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "# ^^^ gets map to previous decoder output during rollout - but during training we want to \n",
    "#   input the target inspite of whatever the decoder output is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random initialization of embedding\n",
    "# word embedding help us reduce the dimension of data for network training\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to understand how this embedding look up works ??\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder cell - using an LSTMCell\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "# defined attention length randomnly - need to analysis the input data and maybe define based on that\n",
    "attention_length = 10 \n",
    "# add a attention wrapper around encoder cell\n",
    "encoder_cell_w_attention = tf.contrib.rnn.AttentionCellWrapper(encoder_cell, attention_length, state_is_tuple=True)\n",
    "# define encoder rnn\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell_w_attention, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define decoder cell - using an LSTMCell\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "decoder_cell_attn = tf.contrib.rnn.AttentionCellWrapper(decoder_cell, attention_length, state_is_tuple=True)\n",
    "# define decoder RNN\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell_attn, decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get batch data\n",
    "def next_feed(batch_seq, input_seqs, output_seqs):\n",
    "    start = batch_seq*10\n",
    "    end = (batch_seq+1)*10\n",
    "    batch_ = input_seqs[start:end]\n",
    "    #print(batch_)\n",
    "    dbatch_ = output_seqs[start:end]\n",
    "    #print(batch_)\n",
    "    encoder_inputs_, _ = helpers.batch(batch_)\n",
    "    decoder_targets_, _ = helpers.batch(dbatch_)\n",
    "    decoder_inputs_, _ = helpers.batch(dbatch_)\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch 1:\n",
      "batch 0\n",
      "  minibatch loss: 4.1042890548706055\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [33 36 36  5 19 19 19 19 20 19  4 55 19 19 19 32 43 43  7  7  7  7 18 18 16\n",
      " 26 26 26  7 36 48 12 52  4 55 55 55 26 26 25 35 25 25 37 54 37 21 36 37 46\n",
      " 35 36 36 36 36  9  6  7 15  9 16  1 43  7 29  7  7 36 36 56 56]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [52 58 25 25 25 36  8  8  8 19 19 20 37 25  7 11 36 36 20  4 19 26 16 26 26\n",
      " 26 26 46  7  7 18 36 37 37 54 26 26 54 37 36 36 55 32 32 26 32 32  7 54 54\n",
      " 29 54 54 37 37 26 36 36 36 36 36 36 20 33  6  6  6  6  6  6  6]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.3739304542541504\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  1  7  3  1  9  2 11  6  2  9  1  7  5  2 11 11  1  2  1  5  2  1  3  5\n",
      " 12 11  1  3  5  2  1  3  5  1  3  1  6  1  6  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  6  9 11  1  2  2  2  7  1  3  5  2  1  3  5  6  3  6  7  2  1\n",
      "  1  1  9  1  7  1  6 12  1  1  5  6  7  2  1  1  1  1  2  5  9  2  1  3  5\n",
      "  5  2  2  2  3  9  1  3  2  4  2  1  6  3  6  7 12  1 11  2  7  7  6  7  5]\n",
      "\n",
      "==> epoch 2:\n",
      "batch 0\n",
      "  minibatch loss: 1.4293091297149658\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.3967737555503845\n",
      "\n",
      "==> epoch 3:\n",
      "batch 0\n",
      "  minibatch loss: 0.6873144507408142\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.17928390204906464\n",
      "\n",
      "==> epoch 4:\n",
      "batch 0\n",
      "  minibatch loss: 0.5312670469284058\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.10163658857345581\n",
      "\n",
      "==> epoch 5:\n",
      "batch 0\n",
      "  minibatch loss: 0.4593299925327301\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.06318138539791107\n",
      "\n",
      "==> epoch 6:\n",
      "batch 0\n",
      "  minibatch loss: 0.4179428815841675\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.04070732370018959\n",
      "\n",
      "==> epoch 7:\n",
      "batch 0\n",
      "  minibatch loss: 0.39047831296920776\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.025906171649694443\n",
      "\n",
      "==> epoch 8:\n",
      "batch 0\n",
      "  minibatch loss: 0.3643299341201782\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.018390530720353127\n",
      "\n",
      "==> epoch 9:\n",
      "batch 0\n",
      "  minibatch loss: 0.3378608822822571\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.013644624501466751\n",
      "\n",
      "==> epoch 10:\n",
      "batch 0\n",
      "  minibatch loss: 0.313148558139801\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.010409882292151451\n",
      "\n",
      "==> epoch 11:\n",
      "batch 0\n",
      "  minibatch loss: 0.2875397503376007\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 28  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.008132686838507652\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "\n",
      "==> epoch 12:\n",
      "batch 0\n",
      "  minibatch loss: 0.26118889451026917\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.006341204978525639\n",
      "\n",
      "==> epoch 13:\n",
      "batch 0\n",
      "  minibatch loss: 0.2346407026052475\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.004940499551594257\n",
      "\n",
      "==> epoch 14:\n",
      "batch 0\n",
      "  minibatch loss: 0.20821133255958557\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0039016364607959986\n",
      "\n",
      "==> epoch 15:\n",
      "batch 0\n",
      "  minibatch loss: 0.18295127153396606\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.003090345999225974\n",
      "\n",
      "==> epoch 16:\n",
      "batch 0\n",
      "  minibatch loss: 0.1586313247680664\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.002508407924324274\n",
      "\n",
      "==> epoch 17:\n",
      "batch 0\n",
      "  minibatch loss: 0.13772781193256378\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0020323563367128372\n",
      "\n",
      "==> epoch 18:\n",
      "batch 0\n",
      "  minibatch loss: 0.11583836376667023\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0016767869237810373\n",
      "\n",
      "==> epoch 19:\n",
      "batch 0\n",
      "  minibatch loss: 0.10110054910182953\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0013988753780722618\n",
      "\n",
      "==> epoch 20:\n",
      "batch 0\n",
      "  minibatch loss: 0.08089171350002289\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.001210475922562182\n",
      "\n",
      "==> epoch 21:\n",
      "batch 0\n",
      "  minibatch loss: 0.06982684880495071\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.000987151637673378\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "\n",
      "==> epoch 22:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.057152725756168365\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0008437253418378532\n",
      "\n",
      "==> epoch 23:\n",
      "batch 0\n",
      "  minibatch loss: 0.0478467158973217\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0007341630407609046\n",
      "\n",
      "==> epoch 24:\n",
      "batch 0\n",
      "  minibatch loss: 0.040010400116443634\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0006296772044152021\n",
      "\n",
      "==> epoch 25:\n",
      "batch 0\n",
      "  minibatch loss: 0.03719300404191017\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.0005773797747679055\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 200\n",
    "batches_in_epoch = 199\n",
    "writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "\n",
    "try:\n",
    "    for epoch in range(25):\n",
    "        print('==> epoch {}:'.format(epoch + 1))\n",
    "        for batch in range(max_batches):\n",
    "            #print(input_seqs)\n",
    "            fd = next_feed(batch, input_seqs, output_seqs)\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                if epoch == 0 or epoch == 10 or epoch == 20 or epoch == 24:\n",
    "                    for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                        print('  sample {}:'.format(i + 1))\n",
    "                        print('    input     > {}'.format(inp))\n",
    "                        print('    predicted > {}'.format(pred))\n",
    "                        if i >= 1:\n",
    "                            break\n",
    "                print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0006 after 50000 examples (batch_size=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125a8748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
