{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports\n",
    "import keras text processing library to transform text (sentence) to sequence  \n",
    "ref : [Creating sequence vector from text in Python](https://stackoverflow.com/questions/38302280/creating-sequence-vector-from-text-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > project gutenberg’s alice’s adventures in wonderland , by lewis carroll\n",
      "    seq   > [56, 1318, 262, 355, 13, 493, 1, 67, 829, 830]\n",
      "  line 2:\n",
      "    text  > this ebook is for the use of anyone anywhere at no cost and with\n",
      "    seq   > [30, 494, 39, 32, 2, 164, 8, 716, 1016, 24, 57, 831, 5, 23]\n",
      "  line 3:\n",
      "    text  > almost no restrictions whatsoever . you may copy it , give it away or\n",
      "    seq   > [495, 57, 1319, 1320, 3, 14, 188, 356, 10, 1, 326, 10, 182, 35]\n",
      "  line 4:\n",
      "    text  > re - use it under the terms of the project gutenberg license included\n",
      "    seq   > [1321, 25, 164, 10, 217, 2, 218, 8, 2, 56, 52, 286, 1017]\n",
      "  line 5:\n",
      "    text  > with this ebook or online at www . gutenberg . org\n",
      "    seq   > [23, 30, 494, 35, 832, 24, 1018, 3, 52, 3, 456]\n"
     ]
    }
   ],
   "source": [
    "# pre process the input data : alice.en\n",
    "with open('./data/alice.en') as f:\n",
    "    input_lines = f.read().splitlines()\n",
    "print('no. of lines {}'.format(len(input_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "en_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "en_tokenizer.fit_on_texts(input_lines)\n",
    "\n",
    "# get sequences\n",
    "input_seqs = en_tokenizer.texts_to_sequences(input_lines)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(input_lines[:5], input_seqs[:5])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3374"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "len(en_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2791\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > scw%57x ’6x5?e5c’”u 4-f75”u 4t/5?x6c5u f? rw?t5c-4?t $ e[ -5rfu 74ccw--\n",
      "    seq   > [56, 1318, 262, 355, 13, 493, 1, 67, 829, 830]\n",
      "  line 2:\n",
      "    text  > x]fu 5eww! fu ;wc x]5 6u5 w; 4?[w?5 4?[r]5c5 4x ?w 7wux 4?t rfx]\n",
      "    seq   > [30, 494, 39, 32, 2, 164, 8, 716, 1016, 24, 57, 831, 5, 23]\n",
      "  line 3:\n",
      "    text  > 4-:wux ?w c5uxcf7xfw?u r]4xuw5/5c q [w6 :4[ 7ws[ fx $ ’f/5 fx 4r4[ wc\n",
      "    seq   > [495, 57, 1319, 1320, 3, 14, 188, 356, 10, 1, 326, 10, 182, 35]\n",
      "  line 4:\n",
      "    text  > c5 1 6u5 fx 6?t5c x]5 x5c:u w; x]5 scw%57x ’6x5?e5c’ -f75?u5 f?7-6t5t\n",
      "    seq   > [1321, 25, 164, 10, 217, 2, 218, 8, 2, 56, 52, 286, 1017]\n",
      "  line 5:\n",
      "    text  > rfx] x]fu 5eww! wc w?-f?5 4x rrr q ’6x5?e5c’ q wc’\n",
      "    seq   > [23, 30, 494, 35, 832, 24, 1018, 3, 52, 3, 456]\n"
     ]
    }
   ],
   "source": [
    "# pre process the output data : alice.x\n",
    "with open('./data/alice.x') as f:\n",
    "    output_lines = f.read().splitlines()\n",
    "print(len(output_lines))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "x_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "x_tokenizer.fit_on_texts(output_lines)\n",
    "\n",
    "# get sequences:\n",
    "output_seqs = x_tokenizer.texts_to_sequences(output_lines)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(output_lines[:5], output_seqs[:5])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# use helper method from for padding : https://github.com/ematvey/tensorflow-seq2seq-tutorials\n",
    "import helpers\n",
    "\n",
    "#start setup of tf network graph\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "#EOS = 1 not using any end of sentence identifier\n",
    "\n",
    "vocab_size = len(en_tokenizer.word_index) + 1\n",
    "input_embedding_size = 20 # random value : need to study how to set correct value\n",
    "\n",
    "encoder_hidden_units = 20 # random value\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define placeholder for encoder input, decoder targets and decoder inputs \n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the encoder network - LSTM cell\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "del encoder_outputs # only encoder final state is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the decoder network - LSTM cell\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")\n",
    "\n",
    "\n",
    "dynamic_rnn(\n",
    "    cell,\n",
    "    inputs,\n",
    "    sequence_length=None,\n",
    "    initial_state=None,\n",
    "    dtype=None,\n",
    "    parallel_iterations=None,\n",
    "    swap_memory=False,\n",
    "    time_major=False,\n",
    "    scope=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup logits layer\n",
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup loss function \n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize gloabal variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to get individual batch data\n",
    "def next_feed(batch_seq, input_seqs, output_seqs):\n",
    "    start = batch_seq*10\n",
    "    end = (batch_seq+1)*10\n",
    "    batch_ = input_seqs[start:end]\n",
    "    dbatch_ = output_seqs[start:end]\n",
    "    encoder_inputs_, _ = helpers.batch(batch_)\n",
    "    decoder_targets_, _ = helpers.batch(dbatch_)\n",
    "    decoder_inputs_, _ = helpers.batch(dbatch_)\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch 1:\n",
      "batch 0\n",
      "  minibatch loss: 8.125134468078613\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [3070  188  833  833  358 3267 1714 2322  571  571 3106  800  800  800]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [1018 1673 2464  371  567 2463 2463 3234  164  447  447 1280 2998 2998]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 548 1818 1540 1544 2427 2263  322 2260 2260 2325 2325 2325 1288 2623]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 4.829812049865723\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "==> epoch 2:\n",
      "batch 0\n",
      "  minibatch loss: 5.492552280426025\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 4.349637985229492\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "==> epoch 3:\n",
      "batch 0\n",
      "  minibatch loss: 4.974462985992432\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 4.082016468048096\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0]\n",
      "\n",
      "==> epoch 4:\n",
      "batch 0\n",
      "  minibatch loss: 4.697474956512451\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 3.898266553878784\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0]\n",
      "\n",
      "==> epoch 5:\n",
      "batch 0\n",
      "  minibatch loss: 4.523631572723389\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [1 1 1 1 0 1 0 0 1 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [0 1 0 0 0 1 0 1 1 0 0 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [1 0 1 1 0 0 1 1 0 0 1 0 1 1]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 3.698403835296631\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [6 1 1 1 5 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [1 1 2 0 1 0 0 0 1 0 6 6 1 1 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [1 0 6 0 1 1 1 0 0 6 0 1 6 1 0 1 1 1 0 0]\n",
      "\n",
      "==> epoch 6:\n",
      "batch 0\n",
      "  minibatch loss: 4.365518093109131\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [1 1 1 1 1 1 0 0 5 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [1 6 1 1 0 6 1 6 1 0 1 1 0 1]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [5 1 6 1 0 0 5 1 0 0 1 1 1 1]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 3.4466047286987305\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [6 2 1 2 5 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [1 1 2 1 1 1 0 0 1 1 6 6 1 1 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [1 1 6 1 2 2 2 6 1 6 1 1 6 1 1 1 1 1 0 0]\n",
      "\n",
      "==> epoch 7:\n",
      "batch 0\n",
      "  minibatch loss: 4.1818342208862305\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [1 1 1 6 2 6 1 0 5 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [2 6 2 1 1 6 1 6 2 6 6 1 5 2]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [6 6 6 1 0 0 5 1 0 1 1 1 1 1]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 3.186398983001709\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [6 2 1 2 5 6 1 3 4 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 1  2  6  2 10  1  4  0 15  1  1  6  1  1  1  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [7 2 2 1 2 2 2 6 2 6 1 1 6 1 1 8 1 2 0 0]\n",
      "\n",
      "==> epoch 8:\n",
      "batch 0\n",
      "  minibatch loss: 3.9885895252227783\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [8 2 1 6 2 6 1 4 5 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [2 6 2 1 2 6 1 6 2 6 6 1 5 2]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 6  6  6  1  3  0  5  1  0  1 15  2  2  1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 199\n",
      "  minibatch loss: 2.9429357051849365\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [6 2 5 2 5 6 8 3 4 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [15  2  6  2 10  1  4 11 15  1 21  6  1  2  6  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 7  2  2  1  2  2  2  6  2  6  1  2  6  1  1  8  1 10  0  0]\n",
      "\n",
      "==> epoch 9:\n",
      "batch 0\n",
      "  minibatch loss: 3.7997188568115234\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [18  2  5  6 13  6  1  4  5  1  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 2 10  2  1  2  6  8  6  2  6  6  1  5  7]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 6  6  6  1  3  0  6  1 10  1 15 10  2  1]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.7341930866241455\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [31  2  5  2 21  6 18  3  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [15  2  6  2 10  1  4 11 15  1 21  6  0 18  6  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [26  2  2  1  2  2  2  6  2 16  1  2  6  1  1 31 21 10  0  0]\n",
      "\n",
      "==> epoch 10:\n",
      "batch 0\n",
      "  minibatch loss: 3.6382808685302734\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [31  2 21  6 13 10  1  4  5  7  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [10 10  1  1  2 15  8  6  2 24  6 12  5 23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 5  6 13 18  3  0  6  1 10  1 15 10 10  1]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.551894426345825\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [31  2  5  2 21 14 18  3  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [31  2  6  2 10  1  4 11 15  1  1  6  0 18  6  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [26  2  1  1 13  2 11  6  2 16  1 15  6  1  1 31 21 10  0  0]\n",
      "\n",
      "==> epoch 11:\n",
      "batch 0\n",
      "  minibatch loss: 3.4986236095428467\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [31  2 23 10 13 10  1  4  5  7  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [10 10  1 32  2 14  8  6 10 24  6 12  5 23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 1  6 13 18  3  0  6  1 10  1  2 10 10  1]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.3866186141967773\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [31  7  5 16 21 14 18  3  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [31  2  6  2 10  1  4 11 15  1  1  6  0 18  6  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [26  2  1  1 13 16 11  6  2 16  1  8  6  1  1 31 21 10  0  0]\n",
      "\n",
      "==> epoch 12:\n",
      "batch 0\n",
      "  minibatch loss: 3.3750951290130615\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [31  2 24 14 13 10  1  4 21 47  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [10 10 39 32  2 14  8  6 10 24 10 12  5 23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [26 10 24 18  3 14  6  1 10  1  2 10 19 41]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.23345947265625\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [31 16  5 16 21 14 18  3  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [38  2  6  2 10  1  4 11 15  1 26  6 59 18  9  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [26  2  1  1 13 16 11  6  2 16  1  8 28  1  1 31 21 10  0  0]\n",
      "\n",
      "==> epoch 13:\n",
      "batch 0\n",
      "  minibatch loss: 3.266099214553833\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [31  2 24 39 13 10  1  4 21 47  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [30 10 39 32  2 14  8  6 10 24 57  2  5 23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [26 57 24 18  3 14 64  1 10  1  2 10 19 41]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.089108467102051\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [96 16  5 16 64 14 18  3  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [38  2  6  2 10  1  4 11 15  1 26 14 59 18 53  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [26  2 13  1 13 16 11  6  2 19  1  8 28  1  1 31 21 59  0  0]\n",
      "\n",
      "==> epoch 14:\n",
      "batch 0\n",
      "  minibatch loss: 3.1682066917419434\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [31  2 24 39 13 49  1 67 64 47  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [30 10 39 32  2 14  8 23 19 24 57  2  5 23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [26 57 24 18  3 14 64  8 10  1  2 10 19 41]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.9549586772918701\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [119  16  65  63  64  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [38  2 55  2 10  1  4 11 15  1 26 71 59 18 53  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [26  2 13  1 13 63 11  6  2 19  1  8 28  1  1 31 21 59  0  0]\n",
      "\n",
      "==> epoch 15:\n",
      "batch 0\n",
      "  minibatch loss: 3.078456163406372\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [31  2 24 39 13 49  1 67 64 47  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [30 10 39 32  2 16  8 29 19 24 57 16  5 23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [26 57 24 18  3 14 71  8 10  1  2 10 19 41]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 199\n",
      "  minibatch loss: 1.8297041654586792\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [119  16  65  63  46  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [38  2 55  2 10  1  4 11 15  1 26 71 59 18 53  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [26  2 13  1 13 63 11  6  2 19  1 73 28  1  1 31 21 59  0  0]\n",
      "\n",
      "==> epoch 16:\n",
      "batch 0\n",
      "  minibatch loss: 2.994266986846924\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [59  2 24 39 13 49  1 67 64 47  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  10  39  32   2 115   8  29   3  24  57  16   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 26  57  24  18   3  14  71   8  10   1   2  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.714417576789856\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [119  16  65  63  46  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 59   2 146   2  10   1   4  11  15   1  26  71  59  18  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2  13   1  13  63  11   6   2 124   1  73  28   1   1   8  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 17:\n",
      "batch 0\n",
      "  minibatch loss: 2.914822816848755\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [ 59   2  24  39  13  13   1  67 104  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  95  39  32   2 115   8  29   3  24  57  15   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 26  57  24  18   3  14  71  41  10   1   2  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.6073309183120728\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [124  16  65  63  46  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 59   2 146   2  10   1   4  11  15   1  26  71  59  49  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2   8   1  13  63  11   6   2 124   1  73  28   1   1   8  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 18:\n",
      "batch 0\n",
      "  minibatch loss: 2.8385932445526123\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [ 59   2  24  39  13  13   1  67 104  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  95  39  32   2 115   8  29   3  24  57  15   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 26  57  62  18   3  14  71  41  10   1  15  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.5077447891235352\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [124  16  65  63  46  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 59   2 146   2  10   1   4  11  15   1  58  71  59  49  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2   8   1  13  63  11   6   2 124   1  73  28   1   1   8  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 19:\n",
      "batch 0\n",
      "  minibatch loss: 2.7647387981414795\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2  24  39  13  13   1  67 104  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  95  39  32   2 115   8  29   3  24  57  15   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 33  57  62  18   3  14 104  41  10   1  15  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.4155511856079102\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [124  16  65  63 221  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 59   2 146   2  10   1   4  11  15   1  58  50  59  15  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2   8   1  13  63  11   6   2 124   1  73  28   1   1  73  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 20:\n",
      "batch 0\n",
      "  minibatch loss: 2.6925134658813477\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2  24  39  13  13   1  67  64  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  70  39  32   2 115   8  29   3  24  57 228   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 33  57  62  18   3  14  47  41  10   1  15  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.3304760456085205\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [124  16  65  63 221  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231   2 146   2  10   1   4  11  15   1  58  50  59  15  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2   8   1  13  63  11   6   2 124   1  73  28 147   1  73  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 21:\n",
      "batch 0\n",
      "  minibatch loss: 2.620894193649292\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2  24  39  13  13   1  67  64  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  70  39  32   2 115   8  29   3  24  57 228   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 33  57  62  18   3  14  47  41  10   1  15  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.2519071102142334\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [124  16  65  63 221  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231   2 146   2  10   1   4  11  15   1  96  50  59  15  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2   8   1  13  63  11   6   2 124   1  73  28 147   1 255  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 22:\n",
      "batch 0\n",
      "  minibatch loss: 2.549133062362671\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2  24  39  13  13   1  67  64  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  70  39  32   2 115   8  29   3  24  57 228   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 33  57  62  18   3  14 121  41  10   1  15  10 182  35]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 199\n",
      "  minibatch loss: 1.1788928508758545\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [124  16  65  63 221  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231   2 146   2  10   1   4  11  15   1  96  50  59  15  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2  39   1  13  63  11   6   2 124   1  73  28 147   1 255  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 23:\n",
      "batch 0\n",
      "  minibatch loss: 2.476639986038208\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2  24  39  13  13   1  67 236  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  70  39  32   2 115   8  29  19  24  57 228   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 33  57  62  18   3  14 121  41  10   1  15  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.1102595329284668\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [124  16  65  63 221  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231   2 146   2  10   1   4  11  15   1  96  50  59  15  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2  39   1  13  63  11   6   2 124   1  73  28 147   1 255  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 24:\n",
      "batch 0\n",
      "  minibatch loss: 2.4031851291656494\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2  24  39  13  13   1  67 236  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  95  39  32   2 115   8  29  19  24  57 228   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 38  57  62  18   3  14 121  41  10   1   2  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.045332670211792\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [203  16  65  63 130  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231   2 146   2  10   1   4  11  15   1  96 197  59  15  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1  13  63  11   6   2 102   1  73  28 147   1 255  21  59\n",
      "   0   0]\n",
      "\n",
      "==> epoch 25:\n",
      "batch 0\n",
      "  minibatch loss: 2.3285539150238037\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2  24  39  13  13   1  67 236  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  95  39  32   2 164   8  29  19  24  57 228   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 38  57  62  18   3  14 121  41  10   1   2  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.9838026165962219\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [203  16  65  63 130  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231   2 146   2  10   1   4  11  15   1  96 197  59 329  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1   2  63  11   6   2 102   1  73 272 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 26:\n",
      "batch 0\n",
      "  minibatch loss: 2.252460241317749\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2 262  39  13  13   1  67 236  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  95  39  32   2 164   8  29  19  24  57 228   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 38  57  62  18   3  14 188  41  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.9252865314483643\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [203  16  65  63 130  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 256 146   2  10   1   4  11  15   1  96 197  59 329  57   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1   8  63  11   6   2 102   1  73 272 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 27:\n",
      "batch 0\n",
      "  minibatch loss: 2.174445629119873\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2 262  39  13  13   1  67 236  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  95  39  32   2 164   8  29  19  24  57 120   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62  18   3  14 188  41  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.8693112134933472\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [116  16  65  63 130  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2  10   1   4  11  15   1  96 197  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1   8  63  11   6   2 102   1  73 272 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 28:\n",
      "batch 0\n",
      "  minibatch loss: 2.0945472717285156\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   2 262  39  13   6   1  67 236  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  95  39  32   2 164   8  29  19  24  57 120   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62  18   3  14 188  41  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.8156696557998657\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [116   2  65  63 130  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1  96 197  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1   8  63  11   6   2 102   1  73 272 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 29:\n",
      "batch 0\n",
      "  minibatch loss: 2.0129194259643555\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   0 262  39  13   6   1  67   5  72   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8   6  19  24  57 120   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62  18   3  14 188 127  10   1 326  10 182  35]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 199\n",
      "  minibatch loss: 0.7646867632865906\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [116   2  65  63 130  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1  96 197  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1   8  63  11   6   2 102   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 30:\n",
      "batch 0\n",
      "  minibatch loss: 1.929907202720642\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   0 262  39  13   6   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8   6  19  24  57 120   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62  18   3  14 188 127  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.7161374688148499\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [241   2  65  63 421  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1  96 197  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1   8  63  11   6   2 102   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 31:\n",
      "batch 0\n",
      "  minibatch loss: 1.845394253730774\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   0 262  39  13   6   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8   6 374  24  57 120   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188 127  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.6699379682540894\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [241   2  65  63 421  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1  96 197  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1   8  63  11   6   2 102   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 32:\n",
      "batch 0\n",
      "  minibatch loss: 1.7598450183868408\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [108   0 262  39  13   6   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8   6 374  24  57 120   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188 127  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.626035749912262\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [241   2  65  63 421  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1  96 197  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1 550  63  11   6   2 102   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 33:\n",
      "batch 0\n",
      "  minibatch loss: 1.6735833883285522\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [147   0 262  39  13   6   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8   6 374  24  57 594   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188 127  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.5842545628547668\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [241   2  65  63 421  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1  96  14  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1 550  63  11   6   2  15   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 34:\n",
      "batch 0\n",
      "  minibatch loss: 1.5865263938903809\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [358   0 262  39  13 493   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 594   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188 127  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.5444992184638977\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [329   2  65  63 421  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 296  14  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1 550  63  11   6   2  15   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 35:\n",
      "batch 0\n",
      "  minibatch loss: 1.4991540908813477\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [147   0 262  39  13 493   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 594   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188 127  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.5067862868309021\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [329 663  65  63 421  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 296  14  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1 550  63  11   6   2  15   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 36:\n",
      "batch 0\n",
      "  minibatch loss: 1.4113737344741821\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [358   0 262  39  13 493   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 594   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188 127  10   1 326  10 182  35]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 199\n",
      "  minibatch loss: 0.4710385203361511\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [329 663  65  63   5  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 296  14  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1 550  63  11   6   2  15   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 37:\n",
      "batch 0\n",
      "  minibatch loss: 1.323203206062317\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [480   0 262 355  13 493   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 594   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188  29  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.4371505379676819\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [438 663  65  63   5  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 296  14  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1 550  63  11   6   2  15   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 38:\n",
      "batch 0\n",
      "  minibatch loss: 1.2347745895385742\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [718   0 262 355  13 493   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 594   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188  29  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.4050353169441223\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [438 663  65  63   5  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 430  14  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 143   1 550  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 39:\n",
      "batch 0\n",
      "  minibatch loss: 1.1472440958023071\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [718   0 262 355  13 493   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 831   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  62   8   3  14 188  29  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.3745763897895813\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [438 663  65  63  60  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 430  14  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 40:\n",
      "batch 0\n",
      "  minibatch loss: 1.0605275630950928\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [718   0 262 355  13 493   1  67 236 594   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 831   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57 491   8   3  14 188  29  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.3456803858280182\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [438 663  65  63 695  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 430  14  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 41:\n",
      "batch 0\n",
      "  minibatch loss: 0.9756528735160828\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [ 718 1318  262  355   13  493    1   67  236  594    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 831   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57  61   8   3  14 188  29  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.3183935880661011\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [367 663  65  63 695  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 430 910  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 42:\n",
      "batch 0\n",
      "  minibatch loss: 0.8918294906616211\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  236  594    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30  87  39  32   2 164   8  39 374  24  57 831   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57 491   8   3  14 188  29  10   1 326  10 182  35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.29268771409988403\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [367 663  65  63 695  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [231 606 146   2 554   1   4  11  15   1 430 910  59 329 535   0   0   0\n",
      "   0   0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 43:\n",
      "batch 0\n",
      "  minibatch loss: 0.8113440275192261\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  236  594    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [ 30 494  39  32   2 164   8  39 374  24  57 831   5  23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [495  57 491   8   3  14 188  29  10   1 326  10 182  35]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 199\n",
      "  minibatch loss: 0.2686757743358612\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [367 663  65  63 695  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 231  606  146    2  554    1    4   11   15    1 1438  910   59  329  535\n",
      "    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 44:\n",
      "batch 0\n",
      "  minibatch loss: 0.7345508933067322\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [  30  494   39   32    2  164    8   39 1016   24   57  831    5   23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 495   57  491 1320    3   14  188   29   10    1  326   10  182   35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.24614039063453674\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [367 663  65  63 695  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 231  606  146    2  554    1    4   11   15    1 1438  910   59  329  535\n",
      "    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 45:\n",
      "batch 0\n",
      "  minibatch loss: 0.6620574593544006\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [  30  494   39   32    2  164    8   39 1016   24   57  831    5   23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 495   57  491 1320    3   14  188   29   10    1  326   10  182   35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.22517219185829163\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [367 663  65  63 695  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 231  606  146    2  554    1    4   11   15    1 1438  910   59  329  535\n",
      "    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 46:\n",
      "batch 0\n",
      "  minibatch loss: 0.5940454006195068\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 495   57  491 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.20576122403144836\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [367 663  65  63 695  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 231  606  146    2  554    1    4   11   15    1 1438  910   59  329  535\n",
      "    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 47:\n",
      "batch 0\n",
      "  minibatch loss: 0.5311663746833801\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.18774476647377014\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [  6 663  65  63 695  14  18   3   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 231  606  146    2  554    1    4   11   15    1 1438  910   59  329  535\n",
      "    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 48:\n",
      "batch 0\n",
      "  minibatch loss: 0.47327929735183716\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.17103928327560425\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [2095  663   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 49:\n",
      "batch 0\n",
      "  minibatch loss: 0.42127105593681335\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 199\n",
      "  minibatch loss: 0.15563812851905823\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [2095  663   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n",
      "==> epoch 50:\n",
      "batch 0\n",
      "  minibatch loss: 0.37500235438346863\n",
      "  sample 1:\n",
      "    input     > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "    predicted > [  56 1318  262  355   13  493    1   67  829  830    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "    predicted > [  30  494   39   32    2  164    8  716 1016   24   57  831    5   23]\n",
      "  sample 3:\n",
      "    input     > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "    predicted > [ 495   57 1319 1320    3   14  188  356   10    1  326   10  182   35]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 0.14145781099796295\n",
      "  sample 1:\n",
      "    input     > [2850 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [2095 2851   65   63  695   14   18    3    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "    predicted > [ 231  606  146    2  554    1    4   11   15    1 1438 1734   59  329  535\n",
      "    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "    predicted > [ 26   2 620   1 964  63  11   6   2 982   1  73 383 147   1 255  21 187\n",
      "   0   0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "batch_size = 10\n",
    "max_batches = 200\n",
    "batches_in_epoch = 199\n",
    "num_epoch = 50 # tried many no. of epoch 10 - 50 and after 50 seems to give very less error\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epoch):\n",
    "        print('==> epoch {}:'.format(epoch + 1))\n",
    "        for batch in range(max_batches):\n",
    "            #print(input_seqs)\n",
    "            fd = next_feed(batch, input_seqs, output_seqs)\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.1423 after 100000 examples (batch_size=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FdX5P/DPkwXCvoaUPcgioLJGQUCrIotgtbZScal7\n+dZiF61WwGptpRWXn0urraaKaFVUBFcEBEFQ9rCENQQCgYQlK0nIvtzz++NOwl2TucmdOzM3n/fr\nlZdzz52Z+0wGn5x75iyilAIREdlHhNkBEBFRYJi4iYhshombiMhmmLiJiGyGiZuIyGaYuImIbIaJ\nm4jIZpi4iYhshombiMhmoow4adeuXVV8fLwRpyYiCks7duzIVUrF6tnXkMQdHx+PpKQkI05NRBSW\nROS43n3ZVEJEZDNM3ERENsPETURkM0zcREQ2w8RNRGQzTNxERDbDxE1EZDOWSdzlVTV4Y30afjic\na3YoRESWpitxi8hDIrJfRPaJyGIRiQl2IC0iI/DMihTc8dbWYJ+aiCisNJi4RaQngN8BSFBKXQwg\nEsDMoAcSIXXbVTWOYJ+eiChs6G0qiQLQSkSiALQGcMqIYBL6dgIApOUUG3F6IqKw0GDiVkqdBPAC\ngBMATgMoVEp947mfiMwSkSQRScrJyWlUMEXlVQCAqS9/36jjiYiaAz1NJZ0A3AigH4AeANqIyB2e\n+ymlEpVSCUqphNhYXRNceZkxunejjiMiak70NJVcC+CYUipHKVUFYBmAcUYEM6xXByNOS0QUVvQk\n7hMAxopIaxERABMBHDQimIT4zkaclogorOhp494K4BMAOwHs1Y5JNCKYSK1nyXUX/8iI0xMRhQVd\nCykopf4C4C8GxwIAGNCtLSJEGt6RiKiZsszIyVotIiNQUV1jdhhERJZlyNJlTXHgdBEOnC5CVY0D\n0ZGW+7tCRGQ6y2bG0krWuomIfLFs4o6MYDs3EZEvlk3cTNtERL5ZNnErswMgIrIo6yZuxdRNROSL\ndRO32QEQEVmUdRM3MzcRkU+WS9wzL9VmCGTiJiLyyXKJ+3RhOQDgaC4XUyAi8sVyiXt9qnMRhp0n\nCkyOhIjImiyXuGs5HGwrISLyxbKJ+4NtJ8wOgYjIkiybuI/llpgdAhGRJelZc/JCEdnt8lMkIn8I\nRXBERORNzwo4h5RSI5RSIwCMBlAK4FOjAvrz9CEAgDvG9jHqI4iIbC3QppKJANKUUseNCAYAfjqy\nJwBgUFw7oz6CiMjWAk3cMwEsNiKQWtERzpAqqx1GfgwRkW3pTtwi0gLADQCW+Hl/logkiUhSTk5O\nowNqGe0Maf5yQxaSJyKyvUBq3NcB2KmUyvL1plIqUSmVoJRKiI2NbXRAMdGRjT6WiKg5CCRx3wqD\nm0mIiKhhuhK3iLQBMAnAMmPDISKihuha5V0pVQKgi8GxEBGRDpYdOUlERL4xcRMR2QwTNxGRzTBx\nExHZjCUT948HxaJT62izwyAisiRLJu5OraPRvhUTNxGRL5ZM3BEiqOEKOEREPlkzcUcIFPM2EZFP\n1kzcApwpKjc7DCIiS7Jk4v44KRM1DoW1KT7nsyIiatYsmbhr3bsoyewQiIgsx9KJm4iIvDFxExHZ\nDBM3EZHNMHETEdkMEzcRkc3oXQGno4h8IiIpInJQRC43OjAiIvJN1wo4AF4BsFIpdbO22ntrA2Mi\nIqJ6NJi4RaQDgCsB3A0ASqlKAJXGhkVERP7oaSrpByAHwNsisktE3tQWD3YjIrNEJElEknJycoIW\n4LZj+UE7FxFRONCTuKMAjALwH6XUSAAlAOZ47qSUSlRKJSilEmJjY5sUVL+u5/8u/OKNzThXXtWk\n8xERhRM9iTsTQKZSaqv2+hM4E7lh+nR2b0LPL6mEg9O8EhEB0JG4lVJnAGSIyIVa0UQAB4wM6o+T\nB7m9/vHz32HqKxuM/EgiItvQ26vktwDe13qUHAVwj3EhARf36OBVlppVbORHEhHZhq7ErZTaDSDB\n4FjqRERIqD6KiMh29Na4LWHF3tPIKa7AtmP5ePU2Q5vZiYgsy1aJ+4H3d9Ztv3qbiYEQEZmIc5UQ\nEdmMrRP3l8mncNGTK1FRXWN2KEREIWPbxL0+NQe/XbwLJZU1OFvCATpE1HzYNnHftXBb3bYCB+cQ\nUfNh28TtakNq8OZGISKyurBI3I8t3Yt3N6dj3DPfmh0KEZHhbNUdsD5Pfr7f7BCIiEIiLGrcnnKL\nK/D8qhROTEVEYSksE/ecpXvx2ro0bErLMzsUIqKgs2zi7t25VaOP/eGI82FltcMRrHCIiCzDsok7\nKqJxoWXkl6K8ypmwkzMKcTSnGM+uTIFSbDYhovBg2YeTkY2cIfCK59bVbb+0JhXLdmXieF4pbh/T\nB706cY1jIrI/y9a4IyU4U7tWVZ9vLqmuceCTHZl8aElEtqarxi0i6QDOAagBUK2UMnxu7vEDuuJQ\n1rmgnU9E8NYPx/DMCmdvk19c2jto5yYiCqVAatxXK6VGhCJpA8DcaYODej6lFPJKKgEA+aWVQT03\nEVEoWbapJDoyOKGdKiwHACgFJG44CgDYf6oIKWeKMP2f36O4ojoon0NEFCp6H04qAN+IiALwhlIq\n0cCYDLF0Z2bd9pfJp1BaUY39p4qwJS0P1w6NMzEyIqLA6E3cE5RSJ0WkG4DVIpKilHJbdl1EZgGY\nBQB9+vQJcphN9/Kaw2aHQEQUFLraI5RSJ7X/ZgP4FMBlPvZJVEolKKUSYmNjgxulAVz7lWQXlWPA\nvK+xJ7PAtHiIiPRqMHGLSBsRaVe7DWAygH1GBwYAM0PQ80ME2HA4F9UOhUWb0g3/PCKiptLTVBIH\n4FNx9quOAvCBUmqloVFpWkYZ9+x0bUp23fYjS5KdG+zeTUQ20GBmVEodVUoN134uUkr9PRSBAcCQ\n7u0N/4y9JwvrtpftOokah+IgHSKyNMt2BwSAXyQY31Ti+dDyjQ1peGRJMj7cnmH4ZxMRNYalE3dE\nI+craYq8YufgnLMcpENEFmXpxG0Gz0kEd2cUoLyqxpxgiIh8YOL2kJZTXLedkV+Kn762EX/hsmhE\nZCFM3B7Wu6wYf8+i7QCAPS4PMImIzMbE7YcIcCS7uOEdiYhCjInbj9fWHqnbPni6CNU1DhSWVpkY\nERGRExO3HyWV7g8kl+08ieF/+wYfJ7GbIBGZi4lbp5QzzkUdvj+ca3IkRNTcMXE3UsqZIpRwLm8i\nMoHlE/fDkwaZHQIAYOHGY3XbBaWVmPry97j/nSQTIyKi5sryifuqC603RezMxC0AgG3p+SZHQkTN\nkeUT97BeHZG+YLrZYdTJKiyva+8mIjKD5RN3rRtH9DA7BADutewah4LyHCNPRGQw2yTu0E83pc/n\nu08hfs5yLGE3QSIKEdskbqvWa2vn837z+2MN7ElEFBy6E7eIRIrILhH5ysiA7CbnXIXb64LSSs4m\nSESGCqTG/XsAB40KpCFWbSr5IvmU2+sRf1uN2/67xaRoiKg50JW4RaQXgOkA3jQ2HPuqqK7Bp7sy\nAQA7T3C1eCIyjt4a98sA/gTA4W8HEZklIkkikpSTk+Nvt7CVnleKF1almh0GETUDDSZuEbkeQLZS\nakd9+ymlEpVSCUqphNhY6w2aCYWTBWV120oprDmQhayichMjIqJwpKfGPR7ADSKSDuBDANeIyHuG\nRlUPE5ahbJRPdmTi/neTMOP1zWaHQkRhpsHErZSaq5TqpZSKBzATwFql1B2GR+bHCzOGW2okpT8H\nThcBAE7kl5ocCRGFG9v0464lNqlxv70x3e31V3tOYcvRPHOCIaKwEhXIzkqp7wB8Z0gkumMw89Mb\n78EPdgGALb4tEJG12abGLXapavuwdEem2SEQURixTeK282ROf1yS7Pb6tXVH8ANX0iGiRrJN4va0\n+qErAQCX9OxgciSB2XI0D8+vOoQ73tpqdihEZFO2SdyeTSUD49ohfcF0TL34RyZF1DivuqweT0TU\nGLZJ3P7Yren7hyPuTSQbUnPw3aFsk6IhIjuyTeK+d3w/tIyKwISBXd3Kbdz0DQC4c+E23P32drPD\nICIbsU3ivqRXBxyafx26tYvx+f6Ui+Iw68oLQhxV09y5cJvb6w2pOUjO4ARVRFQ/2yRuf2qbSvp1\nbYt504aYG0yANqSen4yrusaBOxduw42vbTQxIiKyA9sn7nDx5Bf73V7vPHEWBaWVJkVDRFYWdon7\nG62bYELfTiZHEpgPtp5we/2zf2/CzEQuyEBE3sIucQ/Sugn+5ur+ZofSaHnFzuXQUs6cMzkSIrKi\nsEvcnjq2jkb7mCj07tzK7FB0Gz1/jdvrtzceQ+KGNADA6+vTOOqSqJkLm8St/KwDP7J3R+x5ago6\ntW4R4oiC569fHsA/vk4BACxYkcJRl0TNnO0TtzSwjHBtOv/XrSMBAJ1aRxscUXDNWbpH134Z+aXI\n5mo7RM1CQNO6WpG/mrZnQu/bpQ3WPPxj1DgUpry8IRShBcWH2zPqtmsc/kcbXfHcOgCcNpaoOdCz\n5mSMiGwTkWQR2S8ifw1FYE3lK6EP6NYWbVpGupXZqfdJ/3lfu73OK67Aibz6V9iprHagstrvGs9E\nZEN6mkoqAFyjlBoOYASAqSIy1tiw9GuoqcSfnh1bIX3BdMR3bRPkiEJn7DPf4srn19W7z5h/rMGQ\nJ1eGKCIiCgU9a04qpVSx9jJa+7H8DCENtn1rk5yM7NMxFOEEXebZUlTVNHwbzpZW1dvEQkT2o+vh\npIhEishuANkAViulLNOt4bJ+zqaO8f27+nzfcxIqz+lhb7usD4b37oinb7zIkPiMMuHZ8zXtg9rC\nxIG4/c0tiJ+zPJghEVGI6ErcSqkapdQIAL0AXCYiF3vuIyKzRCRJRJJycnK8T2KQ0X0749D8qbhy\nUKxHQPqOFxF8Pns8fnl5fNBjC5XrXvne7XV5VQ3yS+ofLr/xiO+Fi2scCuVVNUGLjYiCL6DugEqp\nAgDrAEz18V6iUipBKZUQGxvrfbCBWkZFehc2oXXgxhE98Ksr+jX+BCaqqnHgroXbMOrp1Y06fvb7\nOzH4CbaJE1mZnl4lsSLSUdtuBWASgBSjAzPTKzNHIq697+ljra60sgZbj+U3+viV+8/4LC+vqkF6\nbkmjz0tEwaOnxt0dwDoR2QNgO5xt3F8ZG1YQNNBU0lCF3K4LNIz42zd125NfWh+08z6yJBlXvfAd\nSiurg3ZOImqcBgfgKKX2ABgZglhCQm/nwf7d7NlN0PUPTmpWsdt7xRXVSMsuxvDegfekqV1yraLK\nAdfZA0oqqrE2JRs/Gd6jUfESUeBsP+TdnwGxbQEA13ksJqy3In3N4Di8dtsofP+nq4McmTnKq2rw\nwHs7cONrG1FW2fiHj56/vz9/tg+/XbwLezMLmxYgEekWtom7d+fWODR/Km65tHejzzF9WHf07tw6\niFGZZ1NaLnafcC6L9tKa1ICP9/dN5WRBGQCgxKMJpbC0CnOX7WnSHwki8i1sEzfg7G3i2W+7KYvC\nL33gcjz1k6FNC8ok9y5KqttO3HA06Of3fCbw0ppULN6WgY+2n/B9ABE1Wlgn7mAb3bcz+ndra3YY\njXauwveDxfTcEjz88W5U1QQ+p0ntH0LPuWGUn6e7GfmliJ+zHDtPnA34s4jIyfazAwaqfSvntK43\n8GEaAGfb9x+XJGPH8bMoKqtqcH9/Cdnv/h6vNxx2Ds5akpSJUX3cJ/jKKipHbNuWiIhoyvciovDX\n7GrcbVtGYe9Tk/HY1MGNOt7OCzL4cu+i7XXbaw5mh/CT3VP6yYIyjPnHt3jl28MhjIHInppd4gaA\ndjHRja7VXdyzAz64fwxS518X5KjMsSktD2f9rCbvcChsOlL/MmkS4K/R3+RfZwqdi0DU1shdrU/N\naXAIP1Fz0uyaSoJh3ADfE1rZ1dEc3yMiF248hvnLD6JDq2gU6mhGceX5UFgvz5aYssoa3LVwG4b1\n6oAvHpzQqHMShZtmWeMOto9mja1bGi1cbD2ah6PaEHfXpB3ogFK9TeL+8nyNdoK07GKv997dnI49\nmQUBRkRkf0zcLiYPjcN/bh8V8HFjLuiCMf06GxCReW5J3FLv+17rWwaY0QOdUsDX7k9+vh83vLox\nsBMRhQE2lbhIvDPB7BAs5YOtvvtgb0/Px4zXNzfqnIG3iQdu7rI9GNCtHe6bYM8ZHokawhp3kHRq\n0wLd2rXEcz8fZnYohqqsduDAqcAXbtArGHN7Ld6Wgae/OhCEMxFZExN3kERHRmDb49fiF00YYm8H\n4xasRVk9Cy2cLCjDhtQcpOU426T1JuJQ9Ny+5Y3N+OVbllm8iajR2FRioKd/ejGO55bgzR+OmR1K\nUH28PcOrTAE4kVfa4OLFdfsb3CbuS1PmKSeyEta4dfJaGk2HX47tiz9fb8+5Tepz1MeCCufKq3C6\nsKzBYwOtWTeyV2FAbvr3RvSf97XxH0QUJA3WuEWkN4B3AcTBWbFKVEq9YnRgVnLsmWlmh2B5v35v\nJ169zX+XyPWpOXjwg504V97AQgwmrGCx64TvLoU1DoVqh8P30nhEJtJT464G8Eel1FAAYwHMFpHw\nq0bWQ0QaPaAEAN66KwE/PBYe83rXZ+U+72XPlFIoqajGXQu31Zu0G/r9ek5iFQr3LtqOC//M9TfJ\nehpM3Eqp00qpndr2OQAHAfQ0OrBwMnFIHHp1Co95vevz1Z7TXmX//f4oKqq9Zx10TcRrU7Lw2a6T\nPs/pb4h8KKxP9R5+DzinAiiv5wEtkdECejgpIvFwLmPGR/NNsPepySgorcIVz+l7kGdnWUUVWL7n\nlN/3f7d4F75I9v9+LSutAfr4Z/uweNsJHHtmWpO+iRE1lu7ELSJtASwF8AellFdHXhGZBWAWAPTp\n0ydoAVpdXPuWAR/TLiYa7WKiDYjGmp74fL9XWaVWC/dM2q75+UxhOTLOlhoZWqMs3uZ7YJJSClU1\nCi2i+MyfjKUrcYtINJxJ+32l1DJf+yilEgEkAkBCQoKF6kfGOTR/KiKaUOP6bPZ4dGnTolnUvD19\ntvsUbhrVy+/7Gfmllv+9KOXe6yVxw1E8syIFu56YhE5twmv6X7IWPb1KBMBbAA4qpV40PiT7aGpv\ngxGNWG09nNy1cJvf9+pL2hXVNQ33TjGQiO+mm2U7ne30WefKmbjJUHq+040H8EsA14jIbu2H/eMM\nkDr/OmydN7Hudde2ze9//j2ZhTjiYyZA1zw5+/2dSJi/JnRB+eHva6VnUl+bkoX4OctxzEf/d6LG\naLDGrZT6AaEZkdzstYiKQFz7GNw/oR/axkRhSVKm2SGZ4toX1/t9b/YHO0O8Uo9/zmXczv+v4a/V\n7PPdznb85IwC9OvaJgSRUbjjkHcDfPnghHrn82hI7WjL5pq4famsdiCrqBzLfXQ5rPX6+jQsWJFi\neCyCxk2G5dkX/Uh2Ma59cT2+/t0VGNqjfVBio+aBj78NcEmvDrgsiPNzPzxpEKYP6173eoCNV5pv\nijH/+Nbve5vT8kKStF3pbSrx93V11X7ngKUv6+kuSeQLa9w2cNPInujduTWGdj+CnHMVOJFf6rMd\nuLnKyC/Frf/1v/DDupRs3OOyKLLVeCb6c+VV+Mm/fsC/bh2FS3p1MCcosjTWuEPox42YqMrV7KsH\n4KkbLgpSNOGjvh4oWUXleGzpHkM+19+gIH/D871q4n6q4tvT85GeV4oXVx9qQnQUzpi4Q2jRPZca\nOmHVpKFxhp3bjpLS83HV898h+1yFz/f3nypE/JzlAZ830NGSwRpdqZTCX7/cj9Ssc0E5H9kXm0pC\nKNjDo9+6KwETh8ThaE4xThaUYXNaHlYfyArqZ9jZzfUsr1ZeVYPEDUebdP5gTXzleR5/NfmTBWV4\ne2M6Vu07g01zJ/reiZoF1rgt4KaRTZuz64LYtrhiYKwJ8+fZ0383HMX//W9HXTc9Txn5paGpiTey\nl62vz/lo+wkcyWZNvLlg4raAF2YMR8rTU3Xvr3TMuNStXUvcNsY5Z8yTYbiYQ1P8/euDfmf+q3Eo\nfFPPt5aSiuq637/fNu4Ay/X+xa3vtj+2dC8mv7RB34nI9thUYgGREYLICP/D5wNtYXl0yoWYffUA\nAMA/broEn+/2PWUquUuYvxo3j+6N19en+Xz/bEklRj692u/x/m5Tbbln3m3ovgZag3f4SOzb0/MR\n1y4GfbqE/7TCzQlr3Bb2r9tGYtLQOHTv0MqQ81/EQR9ucosr8e1B79p2aaWzln3wtP/V7Q9nnUNJ\nZXDmTwnmFLYzXt+sex1Qsg/WuC1sVJ9O+O+dCX7f11shc00EL98yAlMu+hGKK6qRV1KBqS9/38Qo\nw4uv3+nQJ1fhsamD8exK9wE+rr/XSU1opjDj2cTpwjJERUQgtl3g0xKT+VjjtqFrBncDAMR3CWze\nixuG98BPR/ZEqxaRiG3X0tTVZawqNcv3wKavfIxu/CL5JJRSOJ7nf/KoVfvP4LCfwVJm/vYvf2Yt\nLv27+RN1UeOwxm1Dd4zti58M74GOrZs2e6BnN7TPZo/H8bwSjOjdET9+/rsmnbs5eGzpXhzOKsab\nPxzzu8///W9Ho89vRmKvrHZAQXGBZItj4rYhEfGZtAdqc5hc4GcGOn9NKwO7tcU3D10JEcGI3h1R\nXeO9RmRzt/+U7/btzUfzvMqu/9cP2DpvIk4WlLmVu/YGembFQXyhdUfU00soVMY/uxY55yqQvmC6\n2aFQPZi4w8hNI3tiYLd2Ac9vIeLeg8GzN8O8aYPRuU1LdGvXEnfWs/hBc+RvFshHliTj+8O5bmXZ\n5yqglIKI4I31vgf/VNc4UO2re4gLI5e5zPEzypSshYk7jIiIz6RdOwf0qD6dfB9Xz5fyrfMmIq59\nTHACDENHc3y3b+88ftar7PlVh9AuJgqxbd0fCLpWuMctWOt3iL6ZFfM/fpyMVfvPYN9fp5gXBNXR\ns3TZQgDXA8hWSl1sfEgUbMN7d8SGR69G7876uhW6pvH6kvb9E/rhkl4d4FAKD32U3MQow0tJpe+a\n+LMrUrzee/OHY7jvin7o3qGVW9J2rVkfzyvB7owCQ2LVY+lOzg1vJXpq3IsAvArgXWNDISP5GoDR\no6Mzkd8zPt6tXM9X8aUPjMPovudr8Ezc+vhL6OMWrMUfJw3ye1x9D4vNbCNfvO0EFm1Mx6qHrjQt\nhuZIz9JlG0Qk3vhQKNTax0TX+xAqJtp/b1HXpO3p7nHxuH5Yd2QVVWD2BzubFGNzoRTwwjepbmVr\nDmbj/neS8OZd7n35Xf+wrth7Giv2nQlFiD7NXbbXtM9uzoLWxi0iswDMAoA+ffoE67RkAhHBvGmD\ncdWF3QI+dtE9l7odN/uDYEbW/Kw5mIUrnlvrVpaRX4bt6fm4NL4zHnjf9x/G6hoHCsuqQhGiT1uO\n5uHlNal4774xiIrkcJFgC9pvVCmVqJRKUEolxMY2bcEAMt+sK/tjUFw7n+9dfkEXv8fVl+zH9e+C\nnU9MwvLfTWhyfM1JRn6ZV9mM1zcjq6jcq7xc6+XyxOf7MHq+eQNs/vDhbmw5mu/3QSs1Df8UUkAO\n/G0K3r3vsoCP+2jWWHzwq7Ho3KYFLurh3fNlTBDX6GwufK3BOfiJlQCArzwWVXZoXQxziyvw6trD\nxgen8Xxekp5bgl+9m1T3B4Yah4mbAtK6RRSifXz1ff/+Mfjqt/5r0mPqqaX369oG79x7GQd9BMnq\nA1k4V+4+4dXo+c5ZDR9dkuzVlh5KT36xH6sPZPkcuET6NZi4RWQxgM0ALhSRTBG5z/iwyG7GD+iK\ni3t616TnTRuMR6dc6Pe4LXMnYt0jVyEm2vcQ6z9PH4J4TkkakF+9m+RVdra0ClU1DuQWV7qVP/aJ\ncz3OjUdyG7V4RGN5dlzKKirHjNc3Ia+YTSt6NJi4lVK3KqW6K6WilVK9lFJvhSIwCg+zruxfNze4\nqxmje+GCrm3wow6++4m3iIzAsF4dMGN0b3z36NVo08I9sV/i448E1e+KZ9dh78lCt7KPkjIAACs9\neqZ8usvZb7vGofBWPXOxBMvCjcewPf0sPk5if3E92FRCpnh+xnCsfeQqr/Kfacu4pf79Onzx4AR0\naB3t8/grB3XFhkevxsU9Oae4Xmd8PMwEgOSMAvxvy3G3stp++V8kn8TTXx2oK1+bEto1TbOLytFv\n7nJTBx9ZERM3WcqLt4zw2dY98zJnF9M3fjkav584EA9ePRB9urT2msVu/IAu+OmIHujupyZP3m58\nbaPP8rLKGiSluw/dv3dREpRSyD5X7ta0sinNfV4Wfwsp+x0s5Kf4hyO5UAp4Z1O613vFLsvINTdM\n3GQLj08bgpSnp2LKRT/CQ5MGoZXWdPKTYd3d9hs/oCtenjnSq1tih1a+a+7k35AnV+L9rSe8ys+W\nVuF4Xqlb2W3/3Vq3/eraw8gqcrZVJ/upKftbls2z2F9ezi2uwMV/WYXX1h3xF35YY+ImW4iIEJ8P\nMO8aF4+Up6cifcF0bJ03EQ/8uD8AYMpFcW77tYuJwt6nJuPxaUNCEm84G/X0asx4fbNX+e6MAhRX\nVLv1Wvn1e+cHCB3NKa7r7ZJSzzJwvvh6mAl4d3sEgDUHspDtp1koXDBxk62JnE/oce1j6mpyV13Y\nDekLpiP5L5Px6JQL8d59Y9AuJhqThsZ5nWPpA+Mw97rBIY07HN399jbc/J9NXuXfHcoGAFzz/9bX\ntVU/syLFrS93bcX6iMdqQYE2hDgcCve/m4SZiVsCPNJemLgprHVoFY3ZVw9AvDa1bXzXNkhfMB3v\n3TcGse1aYt60wRjdtxPuvDzeq1385VtG4KcjepgRti0VlFYh5cw5r/K7396OkX/7xqv8s10nAQDD\nnlqFxA3O+ck/2ZGJ9FzvqXLTfJT54tDaVtJ9LCd39Qvf4cXV5vVhDyYmbmqWJgzsiu2PX4tZVzqb\nVlq1iMTmuRPxwozhALSHnCN74uWZI/HYVPfa+O8mDgx5vHZ3ttR73pQ5y/Yifs5yFHkMFnrl28M4\nV16FF785hDlLnf3MkzMK3B6A1rZ9p2adc3tAWd8aFMdyS/DPb71HjW5Ky8X+U4U+jrAuLqRA5OLm\n0b1w8+g88dgXAAAJ3ElEQVRebmUPXNUfndtE47Gle9GjQwwenjQID08ahB3Hz+LnLk0Dv7mqP/79\nXVqoQw47n+46iU+12rirhz7ajf/dNwZ7Mguxcp+zbduhgMXbMnDbGGevo9reLA7lXD+zRVTDddPa\nB6uevZkKS6ugoJq8tqsRmLiJdLjl0j74+ahebr0hRvfthNduG4XHlu5B25ZR+NNU5yjRimpH3Zwh\ngHP06D++TjEj7LCSVVSByS9t8Cqf9+le9OgYg2O5JThTeP6h5JOf78OCnw/z2v9sSSU6tWk4GQ/X\nmnc8E7rD4fzzEBlhxnLOTkzcRDr5mp50+rDumO7SJbH2YenSB8bho+0nkF9SiV9dcQFuH9MXBWVV\nGL/g/BStr902ivOVB8ndb2/3KvtwewZ6d26NPZkFbkvMTXxxPZIev9Yr+aZmnfM7I6arm/6zCckZ\nBabOrSNGdGBPSEhQSUne8yUQNXfZReVIOXMOGWdLcfuYviitrMbxvFI8tzIF6w7lAHDOae4rEbWP\nifJqD6bG6d4hBqcLvbsMbn/8WhzPK0FCfOe6AUYv3TIcN40833xWWx7sxC0iO5RSCQ3vycRNZAlK\nKVTWOJCRX4YB3dpCKYWjuSU4VVCGvy8/iMyzZfhs9nhc++J6r2PvHhePRT5GFlLwfD57PN7ZlI7L\n+3fBo9rEXB1bR2PXE5NQVFbtd2qGQDBxE4Wx8qoaVNY4sOtEAfJLKvCTYT3wyJJkfLb7FK6+MLau\n5v7efWNwx1tbGzgbNcUlPTu4Tdz179tHYdol3es5wj8mbiIC4JwUakNqLsYP6Ir03BL06NgKEwZ2\nxfC/everXvCzSzCHa0g2WWObUAJJ3Hw4SRTGrhkch2sGe48WPfC3KSgorUJkhCCu/fmBR4VlVXhm\nhbMHzANX9cekoXHo16UNRj692u34Id3b4/cTB7gNaafQ0VXjFpGpAF4BEAngTaXUgvr2Z42bKLxk\nF5Uj42wZvkw+hYeuHVTXpvtxUgbmLduLaofCpKFxePbnw9CxVTRuf3Or2yo3T14/FMN7d8QfPtrl\ntYZm786tfK6raVehqHE3mLhFJBJAKoBJADIBbAdwq1LqgL9jmLiJmpezJZXo0CoaEVr3uvKqGuQW\nV+DTnSdxzZBudeuMZuSX4o0NaXhvywlMHhqHxDudeWpdSjbuWXS+J826R65C706t8EXyKTz8cXJd\n+bxpg9GzY2sUlFXi8U/3hfAK9bNK4r4cwFNKqSna67kAoJR6xt8xTNxE1BCllNf0rilnihATFVk3\nt4xSCqlZxUg5U4TqGoWfa6NaHQ6Fdzan45MdmWjdIhJLfj0OAFBV48AfPtyN5XudIysPzZ+KllGR\nUEqh39yv6z5n4d0JGPyj9ujUugWGPHl+sNSoPh1xWb8u6N25VaP/MFglcd8MYKpS6n7t9S8BjFFK\nPejvGCZuIjKTw6FQ5XB4LbRRXlWDzLPOLpe1Siur4VDAlrQ8XOsye+TJgjKUV9Vg9YEs3DehX90i\n2YfOnMPxvBJ8cyALf54+pG5I/N7MQuQUl/t8pqCHKYlbRGYBmAUAffr0GX38+HGvcxERkW+BJG49\nswOeBNDb5XUvrcyNUipRKZWglEqIjY3VFykREQVMT+LeDmCgiPQTkRYAZgL4wtiwiIjInwb7cSul\nqkXkQQCr4OwOuFAptd/wyIiIyCddA3CUUl8D+LrBHYmIyHBcAYeIyGaYuImIbIaJm4jIZpi4iYhs\nxpBpXUUkB0BjR+B0BZDb4F7hhdcc/prb9QK85kD1VUrpGgRjSOJuChFJ0jt6KFzwmsNfc7tegNds\nJDaVEBHZDBM3EZHNWDFxJ5odgAl4zeGvuV0vwGs2jOXauImIqH5WrHETEVE9LJO4RWSqiBwSkSMi\nMsfseJpCRHqLyDoROSAi+0Xk91p5ZxFZLSKHtf920spFRP6pXfseERnlcq67tP0Pi8hdZl2THiIS\nKSK7ROQr7XU/EdmqXddH2uySEJGW2usj2vvxLueYq5UfEpEp5lyJfiLSUUQ+EZEUETkoIpeH830W\nkYe0f9P7RGSxiMSE430WkYUiki0i+1zKgnZfRWS0iOzVjvmniMdSQA1RSpn+A+esg2kALgDQAkAy\ngKFmx9WE6+kOYJS23Q7ONTuHAngOwBytfA6AZ7XtaQBWABAAYwFs1co7Aziq/beTtt3J7Our57of\nBvABgK+01x8DmKltvw7gAW37NwBe17ZnAvhI2x6q3fuWAPpp/yYizb6uBq75HQD3a9stAHQM1/sM\noCeAYwBaudzfu8PxPgO4EsAoAPtcyoJ2XwFs0/YV7djrAorP7F+QdhGXA1jl8nougLlmxxXE6/sc\nzsWWDwHorpV1B3BI234DzgWYa/c/pL1/K4A3XMrd9rPSD5wLbHwL4BoAX2n/IHMBRHneYzinCL5c\n247S9hPP++66nxV/AHTQEpl4lIflfdYSd4aWiKK0+zwlXO8zgHiPxB2U+6q9l+JS7rafnh+rNJXU\n/oOolamV2Z729XAkgK0A4pRSp7W3zgCoXZzO3/Xb6ffyMoA/AXBor7sAKFBKVWuvXWOvuy7t/UJt\nfztdL+CsLeYAeFtrInpTRNogTO+zUuokgBcAnABwGs77tgPhf59rBeu+9tS2Pct1s0riDksi0hbA\nUgB/UEoVub6nnH9qw6JLj4hcDyBbKbXD7FhCLArOr9P/UUqNBFAC51foOmF2nzsBuBHOP1g9ALQB\nMNXUoExi9n21SuLWta6lnYhINJxJ+32l1DKtOEtEumvvdweQrZX7u367/F7GA7hBRNIBfAhnc8kr\nADqKSO1iHa6x112X9n4HAHmwz/XWygSQqZTaqr3+BM5EHq73+VoAx5RSOUqpKgDL4Lz34X6fawXr\nvp7Utj3LdbNK4g6rdS21J8RvATiolHrR5a0vANQ+Wb4Lzrbv2vI7tafTYwEUal/JVgGYLCKdtNrO\nZK3MUpRSc5VSvZRS8XDeu7VKqdsBrANws7ab5/XW/h5u1vZXWvlMrTdCPwAD4XyIY0lKqTMAMkTk\nQq1oIoADCNP7DGcTyVgRaa39G6+93rC+zy6Ccl+194pEZKz2e7zT5Vz6mP0AwKWBfhqcvS/SADxu\ndjxNvJYJcH6N2gNgt/YzDc72vW8BHAawBkBnbX8B8Jp27XsBJLic614AR7Sfe8y+Nh3XfhXO9yq5\nAM7/IY8AWAKgpVYeo70+or1/gcvxj2u/h0MI8Em7Sdc7AkCSdq8/g7P3QNjeZwB/BZACYB+A/8HZ\nMyTs7jOAxXC241fB+c3qvmDeVwAJ2u8wDcCr8HjA3dAPR04SEdmMVZpKiIhIJyZuIiKbYeImIrIZ\nJm4iIpth4iYishkmbiIim2HiJiKyGSZuIiKb+f93/s1whAV7uAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11169f2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  minibatch loss: 0.2442202866077423\n",
      "  sample 1:\n",
      "    input     > [ 41 443  46  17 108   1   4   2  96  92 180  13  87 440 140   3   5]\n",
      "    predicted > [ 41 443  46  17 108   1   4   2  96  92 180  13  87 440 140   3   5]\n",
      "  sample 2:\n",
      "    input     > [   2  101  216  297    1 1078  288  109    8   77  355    3    4    0    0\n",
      "    0    0]\n",
      "    predicted > [   2  101  216  297    1 1078  288  109    8   77  355    3    4    0    0\n",
      "    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 41  65 179  14  95 355  20 287 112  30 753   1   4  11   0   0   0]\n",
      "    predicted > [ 41  65 179  14  95 355  20 287 112  30 753   1   4  11   0   0   0]\n",
      "  sample 4:\n",
      "    input     > [  15    7   40  485   21  143  158   57  164  190  147    6 1075    1    0\n",
      "    0    0]\n",
      "    predicted > [  15    7   40  485   21  143  158   57  164  190  147    6 1075    1    0\n",
      "    0    0]\n",
      "  sample 5:\n",
      "    input     > [335  17  16   7 438 516  64   3   4   0   0   0   0   0   0   0   0]\n",
      "    predicted > [335  17  16   7 438 516  64   3   4   0   0   0   0   0   0   0   0]\n",
      "  sample 6:\n",
      "    input     > [1528   28   18    1    4   11    2   96   92    3    0    0    0    0    0\n",
      "    0    0]\n",
      "    predicted > [1528   28   18    1    4   11    2   96   92    3    0    0    0    0    0\n",
      "    0    0]\n",
      "  sample 7:\n",
      "    input     > [ 333    1   57   12    2  355  111    1    4   11    2  101   13   87 2854\n",
      "  140   21]\n",
      "    predicted > [333   1  57  12   2 355 111   1   4  11   2 101  13  87  10 140  21]\n",
      "  sample 8:\n",
      "    input     > [2855  234  122    7 1576   75    3    4    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    predicted > [   7  234  122    7 1576   75    3    4    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "  sample 9:\n",
      "    input     > [  36   15   90 1564   54   22  355  112    2   75   69    9  111    0    0\n",
      "    0    0]\n",
      "    predicted > [  36   15   90 1564   54   22  355  112    2   75   69    9  111    0    0\n",
      "    0    0]\n",
      "  sample 10:\n",
      "    input     > [311   2 169 123   3   9  16   7  40 743  48  10 115  24 111   1   0]\n",
      "    predicted > [311   2 169 123   3   9  16   7  40 743  48  10 115  24 111   1   0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "fd = next_feed(max_batches, input_seqs, output_seqs)\n",
    "\n",
    "print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "predict_ = sess.run(decoder_prediction, fd)\n",
    "for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "    print('  sample {}:'.format(i + 1))\n",
    "    print('    input     > {}'.format(inp))\n",
    "    print('    predicted > {}'.format(pred))\n",
    "    #if i >= 2:\n",
    "    #    break\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
