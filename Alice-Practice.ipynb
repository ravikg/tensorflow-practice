{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function to sentence(word seq.) to char seq(space is treated as special characted)\n",
    "SPACE = \"_SPACE_\"\n",
    "def char_seq(sentence) :\n",
    "    char_seq_output = \"\"\n",
    "    for c in sentence:\n",
    "        char_seq_output += \" \"\n",
    "        if c == \" \":\n",
    "            char_seq_output += SPACE\n",
    "        else:\n",
    "            char_seq_output += c\n",
    "    return char_seq_output.lstrip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d _SPACE_ u v w x y z', '1 2 3 _SPACE_ 9 8 7']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(char_seq, [\"abcd uvwxyz\", \"123 987\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "{'_space_': 1, 'e': 2, 't': 3, 'a': 4, 'o': 5, 'i': 6, 'n': 7, 'h': 8, 's': 9, 'r': 10, 'd': 11, 'l': 12, 'u': 13, 'c': 14, 'w': 15, 'g': 16, 'y': 17, ',': 18, 'm': 19, 'f': 20, 'p': 21, '’': 22, 'b': 23, 'k': 24, '.': 25, '‘': 26, 'v': 27, '-': 28, '!': 29, ':': 30, 'j': 31, 'q': 32, '?': 33, ';': 34, 'x': 35, '*': 36, 'z': 37, ')': 38, '“': 39, '(': 40, '1': 41, '”': 42, '/': 43, '0': 44, '5': 45, '3': 46, '2': 47, '8': 48, '9': 49, '4': 50, '6': 51, '[': 52, '7': 53, '_': 54, ']': 55, '@': 56, '$': 57, '#': 58, '%': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > project gutenberg’s alice’s adventures in wonderland , by lewis carroll\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > this ebook is for the use of anyone anywhere at no cost and with\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the input data : alice.en\n",
    "with open('./data/alice.en') as f:\n",
    "    input_lines = f.read().splitlines()\n",
    "    input_lines_cs = list(map(char_seq, input_lines))\n",
    "print('no. of lines {}'.format(len(input_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "en_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "en_tokenizer.fit_on_texts(input_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print(en_tokenizer.word_index)\n",
    "\n",
    "# get sequences\n",
    "input_seqs = en_tokenizer.texts_to_sequences(input_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(input_lines[:2], input_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_tokenizer.word_index)\n",
    "type(input_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy\\nprint(input_seqs[:10])\\ninput_seqs_np = numpy.array([numpy.array(xi) for xi in input_seqs])\\nprint(input_seqs_np)\\ntype(input_seqs_np)\\n#input_seqs_tensor = tf.convert_to_tensor(input_seqs_np)\\n#print(input_seqs_tensor)\\nbatched_data = tf.train.batch(\\n    tensors=[input_seqs_np],\\n    batch_size=10,\\n    dynamic_pad=True,\\n    name=\"input_seq_batch\"\\n)\\n# Run the graph\\n# tf.contrib.learn takes care of starting the queues for us\\nres = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\\n# Print the result\\n#print(\"Batch shape: {}\".format(res[0][\"y\"].shape))\\nprint(res[0][\"y\"])\\nprint(res[0])\\nres.shape\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying use batch method from tensorflow\n",
    "'''\n",
    "import numpy\n",
    "print(input_seqs[:10])\n",
    "input_seqs_np = numpy.array([numpy.array(xi) for xi in input_seqs])\n",
    "print(input_seqs_np)\n",
    "type(input_seqs_np)\n",
    "#input_seqs_tensor = tf.convert_to_tensor(input_seqs_np)\n",
    "#print(input_seqs_tensor)\n",
    "batched_data = tf.train.batch(\n",
    "    tensors=[input_seqs_np],\n",
    "    batch_size=10,\n",
    "    dynamic_pad=True,\n",
    "    name=\"input_seq_batch\"\n",
    ")\n",
    "# Run the graph\n",
    "# tf.contrib.learn takes care of starting the queues for us\n",
    "res = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n",
    "# Print the result\n",
    "#print(\"Batch shape: {}\".format(res[0][\"y\"].shape))\n",
    "print(res[0][\"y\"])\n",
    "print(res[0])\n",
    "res.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "vocabulary size: 59\n",
      "vocabulary: {'_space_': 1, '5': 2, 'x': 3, '4': 4, 'w': 5, 'f': 6, '?': 7, ']': 8, 'u': 9, 'c': 10, 't': 11, '-': 12, '6': 13, '7': 14, 'r': 15, '’': 16, '[': 17, '$': 18, ':': 19, ';': 20, 's': 21, '”': 22, 'e': 23, '!': 24, 'q': 25, '_': 26, '/': 27, '1': 28, '#': 29, 'p': 30, '%': 31, 'v': 32, 'k': 33, '9': 34, '“': 35, 'b': 36, '‘': 37, 'd': 38, '8': 39, 'z': 40, 'y': 41, ')': 42, '2': 43, '(': 44, '3': 45, 'l': 46, 'h': 47, 'g': 48, 'o': 49, 'j': 50, ',': 51, 'm': 52, '0': 53, '.': 54, '@': 55, '*': 56, 'n': 57, 'i': 58, 'a': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > scw%57x ’6x5?e5c’”u 4-f75”u 4t/5?x6c5u f? rw?t5c-4?t $ e[ -5rfu 74ccw--\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > x]fu 5eww! fu ;wc x]5 6u5 w; 4?[w?5 4?[r]5c5 4x ?w 7wux 4?t rfx]\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the output data : alice.x\n",
    "with open('./data/alice.x') as f:\n",
    "    output_lines = f.read().splitlines()\n",
    "    output_lines_cs = list(map(char_seq, output_lines))\n",
    "print('no. of lines {}'.format(len(output_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "x_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "x_tokenizer.fit_on_texts(output_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print('vocabulary size: {}'.format(len(x_tokenizer.word_index)))\n",
    "print('vocabulary: {}'.format(x_tokenizer.word_index))\n",
    "\n",
    "# get sequences\n",
    "output_seqs = x_tokenizer.texts_to_sequences(output_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(output_lines[:2], output_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do batching\n",
    "import helpers\n",
    "xt, xlen = helpers.batch(input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  3  4 ...,  6  4  9]\n",
      " [10  8 12 ...,  7 10 13]\n",
      " [ 5  6 19 ..., 14 14 23]\n",
      " ..., \n",
      " [ 1  5  7 ...,  7  1 23]\n",
      " [16  5  5 ..., 16 20  2]\n",
      " [13 24  1 ...,  1  5  1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(xt[:10])\n",
    "print(type(xt))\n",
    "print(type(xt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1 # this is not being used\n",
    "\n",
    "vocab_size = len(en_tokenizer.word_index)\n",
    "input_embedding_size = 16 # 20 or 32\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholders for encoder inputs, decoder input and decoder targets\n",
    "# we don't define the shape (size) of encoder inputs / decoder targets as it will depend on batch size\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "# similarly decoder inputs' shape (size) is dynamic - batch dependent\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "# ^^^ gets map to previous decoder output during rollout - but during training we want to \n",
    "#   input the target inspite of whatever the decoder output is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random initialization of embedding\n",
    "# word embedding help us reduce the dimension of data for network training\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to understand how this embedding look up works ??\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" now we don't delete encoder_output as it will be use in attention for decoder\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define encoder cell - using an LSTMCell\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "# defined attention length randomnly - need to analysis the input data and maybe define based on that\n",
    "attention_length = 10 \n",
    "# add a attention wrapper around encoder cell\n",
    "encoder_cell_w_attention = tf.contrib.rnn.AttentionCellWrapper(encoder_cell, attention_length, state_is_tuple=True)\n",
    "# define encoder rnn\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell_w_attention, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "\n",
    "''' now we don't delete encoder_output as it will be use in attention for decoder'''\n",
    "#del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 20) dtype=float32>),\n",
       " <tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 20) dtype=float32>,\n",
       " <tf.Tensor 'rnn/while/Exit_5:0' shape=(?, 200) dtype=float32>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state # context vector or thought vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define decoder cell - using an LSTMCell\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "decoder_cell_attn = tf.contrib.rnn.AttentionCellWrapper(decoder_cell, attention_length, state_is_tuple=True)\n",
    "# define decoder RNN\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell_attn, decoder_inputs_embedded,\n",
    "    # using only the 1st value of attention based encoder rnn - some issue with size mismatch\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ = input_seqs[:10]#[[6], [3, 4], [9, 8, 7]]\n",
    "dbatch_ = output_seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbatch_, batch_length_ = helpers.batch(batch_)\\nprint('batch_encoded:\\n' + str(batch_))\\n\\n\\ndin_, dlen_ = helpers.batch(dbatch_)\\nprint('decoder inputs:\\n' + str(din_))\\n\\npred_ = sess.run(decoder_prediction,\\n    feed_dict={\\n        encoder_inputs: batch_,\\n        decoder_inputs: din_,\\n    })\\nprint('decoder predictions:\\n' + str(pred_))\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "batch_, batch_length_ = helpers.batch(batch_)\n",
    "print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "\n",
    "din_, dlen_ = helpers.batch(dbatch_)\n",
    "print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "pred_ = sess.run(decoder_prediction,\n",
    "    feed_dict={\n",
    "        encoder_inputs: batch_,\n",
    "        decoder_inputs: din_,\n",
    "    })\n",
    "print('decoder predictions:\\n' + str(pred_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get batch data\n",
    "def next_feed(batch_seq, input_seqs, output_seqs):\n",
    "    start = batch_seq*10\n",
    "    end = (batch_seq+1)*10\n",
    "    batch_ = input_seqs[start:end]\n",
    "    #print(batch_)\n",
    "    dbatch_ = output_seqs[start:end]\n",
    "    #print(batch_)\n",
    "    encoder_inputs_, _ = helpers.batch(batch_)\n",
    "    decoder_targets_, _ = helpers.batch(dbatch_)\n",
    "    decoder_inputs_, _ = helpers.batch(dbatch_)\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch 1:\n",
      "batch 0\n",
      "  minibatch loss: 4.2035064697265625\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [33 33 33 33 37 37 44 43 43 47 43 37 43 43 37 43 43 19 43 43 43 19 19 47 19\n",
      " 19 19 43 43 19 19 37 43 43 43 19 19 43 43 19 43 43 43 43 43 43 43 19 19 19\n",
      " 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 15 15 15]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [10 10 10 10 10 10 10 10 10 17 47 17 10 47 10 10 10 10 10 10 10 10 10 10 10\n",
      " 17 10 15 43 15 43 43 43 43 37 43 43 43 43 43 43 43 43 15 43 43 43 43 43 43\n",
      " 43 43 43 43 43 43 43 43 43 43 43 15 15 15 15 15 15 15 15 15 15]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [42 42 42 10 42  9 47 43 47 47 43  8 42 10  8  8 47 47 47 47 43 43 47 43 43\n",
      " 47 47 47 47 10 48 48  8 33 43 43 43 43 47 47 43 43 43 43 43 43 43 43 43 17\n",
      " 17 43 17 17 17 17 17 15 15 15 15 15 15 17 17 17 17 17 15 17 17]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.225127935409546\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0]\n",
      "\n",
      "==> epoch 2:\n",
      "batch 0\n",
      "  minibatch loss: 2.0957958698272705\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  2  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 1.1658333539962769\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  4  7  7  1  9  9  2  6  9  3  1  5  5  5  7 11  1  8  4  9  2  1  3  5\n",
      "  2 11  1 12  5  5  1  3  8  4  6  1  4  1  3  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  6  1  6 13 11  1  6  2  2  7  1  3  8  2  1  6  8  6  3  6  7  4  1\n",
      "  6  1  8  1  9  4  6 11  1  4  2  6  5  2  1  6  1  3  8  5  9  2  1  3  8\n",
      "  5  5  4  8  3  9  1  3  2  2  2  1  9  3  6 12  7  1  2  5  7  7  6  7  4]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  7  1  3  8  2  1  9  5  2  4  1  6  1  3  6  8 11  1  8  4  9  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1  3  5  2  3  5  6  9  2  1  6  1 12  1  5\n",
      "  2  2  3  1  5  4  5  5  1  6  1  3  2  2  4  9  2  1  4  1  3  2  0  0  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 200\n",
    "batches_in_epoch = 199\n",
    "writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "\n",
    "try:\n",
    "    for epoch in range(2):\n",
    "        print('==> epoch {}:'.format(epoch + 1))\n",
    "        for batch in range(max_batches):\n",
    "            #print(input_seqs)\n",
    "            fd = next_feed(batch, input_seqs, output_seqs)\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.1814 after 4000 examples (batch_size=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114485f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
