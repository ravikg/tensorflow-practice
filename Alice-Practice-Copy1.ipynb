{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' commented to use char level tokenizer of keras\\n# utility function to sentence(word seq.) to char seq(space is treated as special characted)\\nSPACE = \"_SPACE_\"\\ndef char_seq(sentence) :\\n    char_seq_output = \"\"\\n    for c in sentence:\\n        char_seq_output += \" \"\\n        if c == \" \":\\n            char_seq_output += SPACE\\n        else:\\n            char_seq_output += c\\n    return char_seq_output.lstrip(\\' \\')\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' commented to use char level tokenizer of keras\n",
    "# utility function to sentence(word seq.) to char seq(space is treated as special characted)\n",
    "SPACE = \"_SPACE_\"\n",
    "def char_seq(sentence) :\n",
    "    char_seq_output = \"\"\n",
    "    for c in sentence:\n",
    "        char_seq_output += \" \"\n",
    "        if c == \" \":\n",
    "            char_seq_output += SPACE\n",
    "        else:\n",
    "            char_seq_output += c\n",
    "    return char_seq_output.lstrip(' ')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(map(char_seq, [\"abcd uvwxyz\", \"123 987\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'e': 2, 't': 3, 'a': 4, 'o': 5, 'i': 6, 'n': 7, 'h': 8, 's': 9, 'r': 10, 'd': 11, 'l': 12, 'u': 13, 'c': 14, 'w': 15, 'g': 16, 'y': 17, ',': 18, 'm': 19, 'f': 20, 'p': 21, '’': 22, 'b': 23, 'k': 24, '.': 25, '‘': 26, 'v': 27, '-': 28, '!': 29, ':': 30, 'j': 31, 'q': 32, '?': 33, ';': 34, 'x': 35, '*': 36, 'z': 37, ')': 38, '“': 39, '(': 40, '1': 41, '”': 42, '/': 43, '0': 44, '5': 45, '3': 46, '2': 47, '8': 48, '9': 49, '4': 50, '6': 51, '[': 52, '7': 53, '_': 54, ']': 55, '@': 56, '$': 57, '#': 58, '%': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > project gutenberg’s alice’s adventures in wonderland , by lewis carroll\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > this ebook is for the use of anyone anywhere at no cost and with\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "with open('./data/alice.en') as f:\n",
    "    input_lines = f.read().splitlines()\n",
    "en_tokenizer = Tokenizer(lower=True, split=\"\", filters='', char_level=True)\n",
    "en_tokenizer.fit_on_texts(input_lines)\n",
    "# vocabulary:\n",
    "print(en_tokenizer.word_index)\n",
    "# get sequences\n",
    "input_seqs = en_tokenizer.texts_to_sequences(input_lines)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(input_lines[:2], input_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' commented to use char level tokenizer of keras\\n# pre process the input data : alice.en\\nwith open(\\'./data/alice.en\\') as f:\\n    input_lines = f.read().splitlines()\\n    input_lines_cs = list(map(char_seq, input_lines))\\nprint(\\'no. of lines {}\\'.format(len(input_lines)))\\n# tokenizer which makes the text lower case and split by space\\nen_tokenizer = Tokenizer(lower=True, split=\" \", filters=\\'\\')\\nen_tokenizer.fit_on_texts(input_lines_cs)\\n\\n# vocabulary:\\nprint(en_tokenizer.word_index)\\n\\n# get sequences\\ninput_seqs = en_tokenizer.texts_to_sequences(input_lines_cs)\\nprint(\\'sample seq:\\')\\nfor i, (line, seq) in enumerate(zip(input_lines[:2], input_seqs[:2])):\\n    print(\\'  line {}:\\'.format(i + 1))\\n    print(\\'    text  > {}\\'.format(line))\\n    print(\\'    seq   > {}\\'.format(seq))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' commented to use char level tokenizer of keras\n",
    "# pre process the input data : alice.en\n",
    "with open('./data/alice.en') as f:\n",
    "    input_lines = f.read().splitlines()\n",
    "    input_lines_cs = list(map(char_seq, input_lines))\n",
    "print('no. of lines {}'.format(len(input_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "en_tokenizer = Tokenizer(lower=True, split=\" \", filters='')\n",
    "en_tokenizer.fit_on_texts(input_lines_cs)\n",
    "\n",
    "# vocabulary:\n",
    "print(en_tokenizer.word_index)\n",
    "\n",
    "# get sequences\n",
    "input_seqs = en_tokenizer.texts_to_sequences(input_lines_cs)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(input_lines[:2], input_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(en_tokenizer.word_index)\n",
    "#type(input_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines 2791\n",
      "vocabulary size: 59\n",
      "vocabulary: {' ': 1, '5': 2, 'x': 3, '4': 4, 'w': 5, 'f': 6, '?': 7, ']': 8, 'u': 9, 'c': 10, 't': 11, '-': 12, '6': 13, '7': 14, 'r': 15, '’': 16, '[': 17, '$': 18, ':': 19, ';': 20, 's': 21, '”': 22, 'e': 23, '!': 24, 'q': 25, '_': 26, '/': 27, '1': 28, '#': 29, 'p': 30, '%': 31, 'v': 32, 'k': 33, '9': 34, '“': 35, 'b': 36, '‘': 37, 'd': 38, '8': 39, 'z': 40, 'y': 41, ')': 42, '2': 43, '(': 44, '3': 45, 'l': 46, 'h': 47, 'g': 48, 'o': 49, 'j': 50, ',': 51, 'm': 52, '0': 53, '.': 54, '@': 55, '*': 56, 'n': 57, 'i': 58, 'a': 59}\n",
      "sample seq:\n",
      "  line 1:\n",
      "    text  > scw%57x ’6x5?e5c’”u 4-f75”u 4t/5?x6c5u f? rw?t5c-4?t $ e[ -5rfu 74ccw--\n",
      "    seq   > [21, 10, 5, 31, 2, 14, 3, 1, 16, 13, 3, 2, 7, 23, 2, 10, 16, 22, 9, 1, 4, 12, 6, 14, 2, 22, 9, 1, 4, 11, 27, 2, 7, 3, 13, 10, 2, 9, 1, 6, 7, 1, 15, 5, 7, 11, 2, 10, 12, 4, 7, 11, 1, 18, 1, 23, 17, 1, 12, 2, 15, 6, 9, 1, 14, 4, 10, 10, 5, 12, 12]\n",
      "  line 2:\n",
      "    text  > x]fu 5eww! fu ;wc x]5 6u5 w; 4?[w?5 4?[r]5c5 4x ?w 7wux 4?t rfx]\n",
      "    seq   > [3, 8, 6, 9, 1, 2, 23, 5, 5, 24, 1, 6, 9, 1, 20, 5, 10, 1, 3, 8, 2, 1, 13, 9, 2, 1, 5, 20, 1, 4, 7, 17, 5, 7, 2, 1, 4, 7, 17, 15, 8, 2, 10, 2, 1, 4, 3, 1, 7, 5, 1, 14, 5, 9, 3, 1, 4, 7, 11, 1, 15, 6, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# pre process the output data : alice.x\n",
    "with open('./data/alice.x') as f:\n",
    "    output_lines = f.read().splitlines()\n",
    "    #output_lines_cs = list(map(char_seq, output_lines))\n",
    "print('no. of lines {}'.format(len(output_lines)))\n",
    "# tokenizer which makes the text lower case and split by space\n",
    "x_tokenizer = Tokenizer(lower=True, split=\" \", filters='', char_level=True)\n",
    "x_tokenizer.fit_on_texts(output_lines)\n",
    "\n",
    "# vocabulary:\n",
    "print('vocabulary size: {}'.format(len(x_tokenizer.word_index)))\n",
    "print('vocabulary: {}'.format(x_tokenizer.word_index))\n",
    "\n",
    "# get sequences\n",
    "output_seqs = x_tokenizer.texts_to_sequences(output_lines)\n",
    "print('sample seq:')\n",
    "for i, (line, seq) in enumerate(zip(output_lines[:2], output_seqs[:2])):\n",
    "    print('  line {}:'.format(i + 1))\n",
    "    print('    text  > {}'.format(line))\n",
    "    print('    seq   > {}'.format(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 60 # using 60 because 1 - 59 is used in vocab\n",
    "\n",
    "vocab_size = len(en_tokenizer.word_index)+2\n",
    "input_embedding_size = 16 # 20 or 32\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholders for encoder inputs, decoder input and decoder targets\n",
    "# we don't define the shape (size) of encoder inputs / decoder targets as it will depend on batch size\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "# similarly decoder inputs' shape (size) is dynamic - batch dependent\n",
    "''' disable for new decoder rnn\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "'''\n",
    "# ^^^ gets map to previous decoder output during rollout - but during training we want to \n",
    "#   input the target inspite of whatever the decoder output is\n",
    "\n",
    "## adding placeholder for encoder inputs length, to use it for new decoder rnn\n",
    "# where this can be used as a reference for decoder input/time step length\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random initialization of embedding\n",
    "# word embedding help us reduce the dimension of data for network training\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' disable for new decoder rnn\\ndecoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to understand how this embedding look up works ??\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "''' disable for new decoder rnn\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" now we don't delete encoder_output as it will be use in attention for decoder\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define encoder cell - using an LSTMCell\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "# defined attention length randomnly - need to analysis the input data and maybe define based on that\n",
    "attention_length = 10 \n",
    "# add a attention wrapper around encoder cell\n",
    "encoder_cell_w_attention = tf.contrib.rnn.AttentionCellWrapper(encoder_cell, attention_length, state_is_tuple=True)\n",
    "# define encoder rnn\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell_w_attention, encoder_inputs_embedded,\n",
    "    sequence_length=encoder_inputs_length, # added this to use it back in decoder scratch rnn\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "\n",
    "''' now we don't delete encoder_output as it will be use in attention for decoder'''\n",
    "#del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' disable for new decoder rnn\\n# test on test data\\n# get the test batch\\ntotal_data_size = len(input_seqs) # 2791\\ntraining_data_size = max_batches * batch_size # 2000\\n# test_data = total_data - training_data\\ntest_input_seqs  = input_seqs[training_data_size:]\\ntest_output_seqs = output_seqs[training_data_size:]\\n\\n# sort the test data on len and observe\\ntiss = sorted(test_input_seqs, key=len)\\ntoss = sorted(test_output_seqs, key=len)\\n\\n# no. of batchess in test data\\ntest_batches = len(test_input_seqs) / batch_size\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' disable for new decoder rnn\n",
    "# test on test data\n",
    "# get the test batch\n",
    "total_data_size = len(input_seqs) # 2791\n",
    "training_data_size = max_batches * batch_size # 2000\n",
    "# test_data = total_data - training_data\n",
    "test_input_seqs  = input_seqs[training_data_size:]\n",
    "test_output_seqs = output_seqs[training_data_size:]\n",
    "\n",
    "# sort the test data on len and observe\n",
    "tiss = sorted(test_input_seqs, key=len)\n",
    "toss = sorted(test_output_seqs, key=len)\n",
    "\n",
    "# no. of batchess in test data\n",
    "test_batches = len(test_input_seqs) / batch_size\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' disable for new decoder rnn\\nfd = next_feed(0, tiss, toss, batch_size)\\nprint(tiss[0])\\nprint(len(fd[encoder_inputs]))\\nprint(fd[encoder_inputs])\\nprint(fd[encoder_inputs].size)\\nprint(fd[encoder_inputs].shape)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' disable for new decoder rnn\n",
    "fd = next_feed(0, tiss, toss, batch_size)\n",
    "print(tiss[0])\n",
    "print(len(fd[encoder_inputs]))\n",
    "print(fd[encoder_inputs])\n",
    "print(fd[encoder_inputs].size)\n",
    "print(fd[encoder_inputs].shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" disable for new decoder rnn\\ntest_loss_track_x = []\\ntest_loss_track_y = []\\n\\n#fd = next_feed(max_batches, input_seqs, output_seqs, batch_size)\\nfor batch in range(int(test_batches)):\\n    fd = next_feed(batch, tiss, toss, batch_size)\\n    print('batch {}'.format(batch))\\n    ll = len(fd[encoder_inputs])\\n    print('len {}'.format(ll))\\n    #print(len(fd[encoder_inputs]))\\n    #if(batch == 62):\\n    #    print(fd)\\n    l = sess.run(loss, fd)\\n    #print('  minibatch loss: {}'.format(l))\\n    test_loss_track_x.append(ll)\\n    test_loss_track_y.append(l)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' disable for new decoder rnn\n",
    "test_loss_track_x = []\n",
    "test_loss_track_y = []\n",
    "\n",
    "#fd = next_feed(max_batches, input_seqs, output_seqs, batch_size)\n",
    "for batch in range(int(test_batches)):\n",
    "    fd = next_feed(batch, tiss, toss, batch_size)\n",
    "    print('batch {}'.format(batch))\n",
    "    ll = len(fd[encoder_inputs])\n",
    "    print('len {}'.format(ll))\n",
    "    #print(len(fd[encoder_inputs]))\n",
    "    #if(batch == 62):\n",
    "    #    print(fd)\n",
    "    l = sess.run(loss, fd)\n",
    "    #print('  minibatch loss: {}'.format(l))\n",
    "    test_loss_track_x.append(ll)\n",
    "    test_loss_track_y.append(l)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' disable for new decoder rnn\\nprint(test_loss_track_x[0:10])\\nprint(test_loss_track_y[0:10])\\nprint(len(test_loss_track_x))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' disable for new decoder rnn\n",
    "print(test_loss_track_x[0:10])\n",
    "print(test_loss_track_y[0:10])\n",
    "print(len(test_loss_track_x))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" disable for new decoder rnn\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nplt.plot(test_loss_track_x, test_loss_track_y, 'ro')\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' disable for new decoder rnn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_loss_track_x, test_loss_track_y, 'ro')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" disable for new decoder rnn\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nplt.plot(test_loss_track_x, test_loss_track_y, 'ro')\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' disable for new decoder rnn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_loss_track_x, test_loss_track_y, 'ro')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Different Decoder\n",
    "Defining a new decoder using raw_rnn in which input to next timestep if output of previous timestep unlike earlier when the decoder input for each timestep was given.\n",
    "\n",
    "###### following catch or issue\n",
    "* how to define length of decoder output / length of time steps / how far to run the decoder\n",
    "    * stop after fix no. of run\n",
    "    * let the network stop on its own?? - how??\n",
    "* inital hidden state is same as earlier decoder rnn, which is: encoder's final state\n",
    "* can we speedup training by providing decoder input in this layer or mix its with decoder output??\n",
    "\n",
    "Ref: [Advanced dynamic seq2seq with TensorFlow](https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/2-seq2seq-advanced.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set decoder cell\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "decoder_cell_w_attention = tf.contrib.rnn.AttentionCellWrapper(decoder_cell, attention_length, state_is_tuple=True)\n",
    "#get maximum time step from input data use that to set the decoder output timestep\n",
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now define it a fixed length based on encoder input length e.g. +3\n",
    "decoder_lengths = encoder_inputs_length + 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define wieght and bias for the hidden layer  to output layer which map it to vocab \n",
    "# unlike earlier we used the existing linear layer\n",
    "# this will be clear later why we did this but for now it is needed as we will be giving input to next decoder time-step\n",
    "# and we have to pass this W and b in each run and earlier it was used internally and we never needed it\n",
    "# but now we are defining the decoder rnn from scratch we also need to do this\n",
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoder will work on single vector of column of size: batch_size in a single time step\n",
    "# EOS = end of sentence tag: defined but not used earlier - need to check how it can be used\n",
    "assert EOS == 60 and PAD == 0\n",
    "\n",
    "# defining for particular timestep of the current batch_size\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "# embedding of the above\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transition function\n",
    "Now we are going to use tf.nn.raw_rnn to create our decoder rnn so that we are able to pass output(generated token) of previous timestep to current timestep. For the we need to define loop transition function.\n",
    " * initial loop trasition function i.e. for 0th timestep \n",
    " * other timestep loop transition function\n",
    " \n",
    "Loop transition function is a mapping:  \n",
    "(time, previous_cell_output, previous_cell_state, previous_loop_state) -> (elements_finished, input, cell_state, output, loop_state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial loop transition function\n",
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    initial_input = eos_step_embedded # in current scenario it will map to vocab entry with key 1\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None  # we don't need to pass any additional information\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop function for transition\n",
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "    # given output (hidden state form) from time t transform into input for t+1 cell\n",
    "    ##  output(t) -> output projection(t) -> prediction(t) (argmax) -> input embedding(t+1) -> input(t+1)\n",
    "    def get_next_input() :\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        # out of possible output return max valued output\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        output = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return output\n",
    "    elements_finished = (time >= decoder_lengths) # this operation produces boolean tensor of [batch_size]\n",
    "                                                  # defining if corresponding sequence has ended\n",
    "\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    next_input = tf.cond(finished, lambda: pad_step_embedded, get_next_input) # if it is already finished\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, \n",
    "            next_input,\n",
    "            state,\n",
    "            output,\n",
    "            loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the above 2 loop functions and define loop fn for rnn \n",
    "\n",
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "# and create the rnn using above loop fn\n",
    "with tf.variable_scope(\"myrnn\", reuse=None) as scope:\n",
    "    decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell_w_attention, loop_fn)\n",
    "#\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temporary flatten to do logits calculation and prediction\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining the entropy function\n",
    "# i.e. decoder_prediction diff decoder_target energy calculation\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defined feed func for new decoder rnn\n",
    "# get batch data\n",
    "def next_feed(batch_seq, input_seqs, output_seqs, batch_size):\n",
    "    start = batch_seq * batch_size\n",
    "    end = (batch_seq + 1) * batch_size\n",
    "    batch_ = input_seqs[start:end]\n",
    "    dbatch_ = output_seqs[start:end]\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch_)\n",
    "    #decoder_targets_, _ = helpers.batch(dbatch_)\n",
    "    decoder_targets_, _ = helpers.batch([(sequence) + [EOS] + [PAD] * 2 for sequence in dbatch_])\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 200)\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "batch_size = 10\n",
    "max_batches = 200\n",
    "batches_in_epoch = 199\n",
    "training_data_size = max_batches * batch_size # 2000\n",
    "\n",
    "## get the validation data\n",
    "vd_batch_size = 200\n",
    "vd = next_feed(0, input_seqs[training_data_size:], output_seqs[training_data_size:], vd_batch_size)\n",
    "print(vd[encoder_inputs].shape)\n",
    "vd_loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch 1:\n",
      "batch 0\n",
      "  minibatch loss: 4.107812404632568\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [42 42 42 42 42  4 43 43 43 43 43 43 24 33 33 26 26 24 26 24 26 24 33 33 33\n",
      " 33 33 54 54 37 24 30 30 30 30 30 30 30  1  1  1  1  0  1  0  1  0  1  0 58\n",
      " 12 12 12  8 12  8 12 46 33 33 54 37 37 59 37 12 12 12 12 12 46 56 56 56]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [10 10 10 60  3  3 30 30 30 30 30 30 30 30 30 30 30  1  1  0  1  0 37  0  0\n",
      "  0 54 37  0  0 21  0  0  1 21  0  0  1  1 12  8 12  8  8  8  8 12  8  8 12\n",
      " 46 16 37 59 37  0 37  0 59 14  1 12 12 12 12 37 12  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [42 42 42 42 43 43 43 43 43 33 33 33 33 33 33 33 33 33 33 33 54 37 37  0 30\n",
      " 30 30 30 30 30 30 30 30 30 30 30 30 30  1  1  0  1  0  1  0  0  1  0 21  0\n",
      "  0 21 12  8  8  8  8  8  0  0 16 57  1  1 37 12 12 12 37 12 12 12  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 3.2443227767944336\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 2:\n",
      "batch 0\n",
      "  minibatch loss: 3.447432518005371\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 3.1287949085235596\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  0  1]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 3:\n",
      "batch 0\n",
      "  minibatch loss: 3.3365085124969482\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  3  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  1  0  0  0  1]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  3  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  1  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 3.0191071033477783\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 3.1978776454925537\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.9077069759368896\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0\n",
      "  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 5:\n",
      "batch 0\n",
      "  minibatch loss: 3.117825508117676\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.8542590141296387\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0\n",
      "  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 6:\n",
      "batch 0\n",
      "  minibatch loss: 3.0182909965515137\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.7727339267730713\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26 26  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60\n",
      "  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 7:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.937173366546631\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.7167885303497314\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26 26  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60\n",
      "  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 8:\n",
      "batch 0\n",
      "  minibatch loss: 2.8591582775115967\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.653886318206787\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 9:\n",
      "batch 0\n",
      "  minibatch loss: 2.7848315238952637\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.6018731594085693\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 10:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.7159221172332764\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.554579496383667\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 11:\n",
      "batch 0\n",
      "  minibatch loss: 2.6490707397460938\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.5099358558654785\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 12:\n",
      "batch 0\n",
      "  minibatch loss: 2.589479446411133\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.4728949069976807\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  3  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 13:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.529200315475464\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.4397637844085693\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 14:\n",
      "batch 0\n",
      "  minibatch loss: 2.4791369438171387\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.410411834716797\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 15:\n",
      "batch 0\n",
      "  minibatch loss: 2.4371843338012695\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.384714365005493\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 16:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.3978028297424316\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.364152431488037\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 17:\n",
      "batch 0\n",
      "  minibatch loss: 2.361996650695801\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.344977855682373\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 18:\n",
      "batch 0\n",
      "  minibatch loss: 2.332702875137329\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.328923225402832\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 19:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.3077917098999023\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.3154473304748535\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 20:\n",
      "batch 0\n",
      "  minibatch loss: 2.2858188152313232\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.303652763366699\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 21:\n",
      "batch 0\n",
      "  minibatch loss: 2.2685415744781494\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2932257652282715\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 22:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.252995014190674\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2851271629333496\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 23:\n",
      "batch 0\n",
      "  minibatch loss: 2.238863468170166\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.277386426925659\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 24:\n",
      "batch 0\n",
      "  minibatch loss: 2.2272353172302246\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.272998332977295\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 25:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.221066474914551\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.267742872238159\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 26:\n",
      "batch 0\n",
      "  minibatch loss: 2.2104992866516113\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2630865573883057\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 27:\n",
      "batch 0\n",
      "  minibatch loss: 2.20307993888855\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2592079639434814\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 28:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.1969103813171387\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.254612445831299\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 29:\n",
      "batch 0\n",
      "  minibatch loss: 2.19020676612854\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2510643005371094\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 30:\n",
      "batch 0\n",
      "  minibatch loss: 2.1834731101989746\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2803893089294434\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 31:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.1852195262908936\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2460379600524902\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 32:\n",
      "batch 0\n",
      "  minibatch loss: 2.176002264022827\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.243256092071533\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 33:\n",
      "batch 0\n",
      "  minibatch loss: 2.1682543754577637\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  5  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.239071846008301\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [26  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 34:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.1638197898864746\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  2  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2361578941345215\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  4  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 35:\n",
      "batch 0\n",
      "  minibatch loss: 2.1607909202575684\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  5  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  8  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2329721450805664\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 36:\n",
      "batch 0\n",
      "  minibatch loss: 2.1569995880126953\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  5  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [26  8  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.227686643600464\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 37:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.1544535160064697\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2254467010498047\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 38:\n",
      "batch 0\n",
      "  minibatch loss: 2.1533830165863037\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [26  6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.219902515411377\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 39:\n",
      "batch 0\n",
      "  minibatch loss: 2.147247552871704\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2158260345458984\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 40:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.149308204650879\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  5  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4 12  5 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.2111942768096924\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26 17  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 41:\n",
      "batch 0\n",
      "  minibatch loss: 2.1439502239227295\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  8  5  1  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.210829496383667\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  6  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 42:\n",
      "batch 0\n",
      "  minibatch loss: 2.139540672302246\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  8  5  1  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4 14 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.203327178955078\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  1  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 43:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.135187864303589\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [ 3  8  5  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.201392650604248\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26 17  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 44:\n",
      "batch 0\n",
      "  minibatch loss: 2.1280219554901123\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21  8  5  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.193800687789917\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26 17  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 3  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 45:\n",
      "batch 0\n",
      "  minibatch loss: 2.1281025409698486\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21  8  5  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  5  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.189298391342163\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26 17  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 46:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.1234233379364014\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21  4 10 10  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.189784288406372\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [23  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 47:\n",
      "batch 0\n",
      "  minibatch loss: 2.132002830505371\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21  4  6 10 10  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.1925246715545654\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 48:\n",
      "batch 0\n",
      "  minibatch loss: 2.125025510787964\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10 10 14 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  1  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.1886186599731445\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  1  1  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 49:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.125098705291748\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10 10 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  1  5  1  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.185822010040283\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n",
      "==> epoch 50:\n",
      "batch 0\n",
      "  minibatch loss: 2.1227433681488037\n",
      "  sample 1:\n",
      "    input     > [21 10  5 31  2 14  3  1 16 13  3  2  7 23  2 10 16 22  9  1  4 12  6 14  2\n",
      " 22  9  1  4 11 27  2  7  3 13 10  2  9  1  6  7  1 15  5  7 11  2 10 12  4\n",
      "  7 11  1 18  1 23 17  1 12  2 15  6  9  1 14  4 10 10  5 12 12]\n",
      "    predicted > [21 10 14 10 10  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 3  8  6  9  1  2 23  5  5 24  1  6  9  1 20  5 10  1  3  8  2  1 13  9  2\n",
      "  1  5 20  1  4  7 17  5  7  2  1  4  7 17 15  8  2 10  2  1  4  3  1  7  5\n",
      "  1 14  5  9  3  1  4  7 11  1 15  6  3  8  0  0  0  0  0  0  0]\n",
      "    predicted > [ 3  8  2  1  1  6  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 4 12 19  5  9  3  1  7  5  1 10  2  9  3 10  6 14  3  6  5  7  9  1 15  8\n",
      "  4  3  9  5  2 27  2 10  1 25  1 17  5 13  1 19  4 17  1 14  5 21 17  1  6\n",
      "  3  1 18  1 16  6 27  2  1  6  3  1  4 15  4 17  1  5 10  0  0]\n",
      "    predicted > [ 4  4  6 14  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0  0  0]\n",
      "\n",
      "batch 199\n",
      "  minibatch loss: 2.1810860633850098\n",
      "  sample 1:\n",
      "    input     > [26  4  7 17  1  9  8 10  6 19 21  1 14  5 13 12 11  1  8  4 27  2  1  3  5\n",
      " 12 11  1 17  5 13  1  3  8  4  3  1 25  1 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [26  4  1  1  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1 22 60  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [26  6 20  1  6 22 11  1 23  2  2  7  1  3  8  2  1 15  8  6  3  6  7 16  1\n",
      " 18  1 22  1  9  4  6 11  1  4 12  6 14  2  1 18  1 15  8  5  9  2  1  3  8\n",
      "  5 13 16  8  3  9  1 15  2 10  2  1  9  3  6 12 12  1 10 13  7  7  6  7 16]\n",
      "    predicted > [26  6  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25\n",
      " 60  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 5  7  1  3  8  2  1  9  5  7 16  1 18  1 26  6 22 11  1  8  4 27  2  1  9\n",
      "  4  6 11  1  3  5  1  3  8  2  1 21  5 10 21  5  6  9  2  1 18  1 39  1 24\n",
      "  2  2 21  1 23  4 14 24  1 18  1 21 12  2  4  9  2  1 30  1 15  2  0  0  0]\n",
      "    predicted > [ 5  5  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 25 60  0  0\n",
      "  0  0  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running the trainning epoch\n",
    "\n",
    "writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "\n",
    "try:\n",
    "    for epoch in range(50):\n",
    "        print('==> epoch {}:'.format(epoch + 1))\n",
    "        for batch in range(max_batches):\n",
    "            #print(input_seqs)\n",
    "            fd = next_feed(batch, input_seqs, output_seqs, batch_size)\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "            #calculate validation loss\n",
    "            vl = sess.run(loss, vd)\n",
    "            vd_loss_track.append(vl)\n",
    "\n",
    "            if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                print('batch {}'.format(batch))\n",
    "                print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "                predict_ = sess.run(decoder_prediction, fd)\n",
    "                for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    input     > {}'.format(inp))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "                print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.1822 after 100000 examples (batch_size=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf1Fv+fKTbAEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113e59b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot trainning loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track, 'b', vd_loss_track, 'r')\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#####\\n# plot trainning loss\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nplt.plot(loss_track, 'b', vd_loss_track, 'r')\\nprint('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#####\n",
    "# plot trainning loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track, 'b', vd_loss_track, 'r')\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
